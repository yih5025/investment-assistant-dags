from datetime import datetime, timedelta
import requests
import os

from airflow import DAG
from airflow.models import Variable
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.exceptions import AirflowSkipException

# í‘œì¤€ ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "..", "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_market_news.sql"), encoding="utf-8") as f:
    UPSERT_SQL = f.read()

default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': None,
    'retry_delay': timedelta(minutes=1),
}

with DAG(
    dag_id='ingest_market_newsapi_to_db_k8s',
    default_args=default_args,
    schedule_interval='@daily',
    catchup=False,
    description='Fetch market-moving news (economics, politics, Fed) via NewsAPI',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['market', 'news', 'newsapi', 'economics', 'politics', 'k8s'],
) as dag:

    create_table = PostgresOperator(
        task_id='create_market_news_table',
        postgres_conn_id='postgres_default',
        sql='create_market_news.sql',
    )

    def fetch_and_upsert_market_news(**context):
        """ê±°ì‹œê²½ì œ ì˜í–¥ ë‰´ìŠ¤ ìˆ˜ì§‘ (NewsAPI)"""
        hook = PostgresHook(postgres_conn_id='postgres_default')
        api_key = Variable.get('NEWSAPI_API_KEY')
        
        # ì‹œê°„ ë²”ìœ„ ì„¤ì • (ì–´ì œë¶€í„° ì˜¤ëŠ˜ê¹Œì§€)
        now = datetime.utcnow()
        since = (now - timedelta(days=1)).isoformat() + "Z"
        until = now.isoformat() + "Z"
        
        # íš¨ê³¼ì ì¸ ê²€ìƒ‰ í‚¤ì›Œë“œ (ì‹œì¥ì— ì˜í–¥ì„ ì£¼ëŠ” ì£¼ìš” ì´ìŠˆë“¤)
        keywords = [
            # ì¤‘ì•™ì€í–‰ ë° í†µí™”ì •ì±…
            "Federal Reserve OR Fed OR interest rate OR inflation OR CPI",
            "ECB OR Bank of Japan OR BOJ OR monetary policy",
            
            # ê±°ì‹œê²½ì œ ì§€í‘œ
            "GDP OR unemployment OR jobs report OR retail sales",
            "housing market OR consumer confidence OR PMI",
            
            # ì •ì¹˜ ë° ì •ì±…
            "Biden OR Trump OR Congress OR stimulus OR infrastructure",
            "debt ceiling OR government shutdown OR election",
            
            # êµ­ì œ ì •ì¹˜/ì™¸êµ
            "China trade OR Russia sanctions OR Ukraine war",
            "OPEC OR oil price OR energy crisis",
            
            # ì£¼ìš” ê¸°ì—… ë° ì‹œì¥
            "earnings OR IPO OR merger OR acquisition",
            "stock market OR Wall Street OR S&P 500",
            
            # ì•”í˜¸í™”í ë° ì‹ ê¸°ìˆ 
            "Bitcoin OR cryptocurrency OR blockchain OR AI regulation"
        ]
        
        print(f"ğŸ“Š {len(keywords)}ê°œ í‚¤ì›Œë“œ ê·¸ë£¹ìœ¼ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
        
        total_articles = 0
        
        for i, keyword_group in enumerate(keywords):
            try:
                # NewsAPI íŒŒë¼ë¯¸í„°
                params = {
                    'q': keyword_group,
                    'from': since,
                    'to': until,
                    'sortBy': 'relevancy',
                    'language': 'en',
                    'apiKey': api_key,
                    'pageSize': 10,  # ê·¸ë£¹ë‹¹ ìµœëŒ€ 10ê°œ ê¸°ì‚¬
                }
                
                # NewsAPI í˜¸ì¶œ
                resp = requests.get(
                    "https://newsapi.org/v2/everything",
                    params=params,
                    timeout=30
                )
                
                # Rate Limit ì²˜ë¦¬
                if resp.status_code == 429:
                    print(f"â° Rate Limit ë„ë‹¬, ì˜¤ëŠ˜ì€ ì—¬ê¸°ê¹Œì§€")
                    raise AirflowSkipException("NewsAPI Rate Limit ì´ˆê³¼")
                
                resp.raise_for_status()
                data = resp.json()
                articles = data.get("articles", [])
                
                # ê° ê¸°ì‚¬ ì €ì¥
                for article in articles:
                    if article.get('url') and article.get('publishedAt'):
                        hook.run(UPSERT_SQL, parameters={
                            'source': article["source"]["name"] if article.get("source") else "",
                            'url': article["url"],
                            'author': article.get("author", ""),
                            'title': article.get("title", ""),
                            'description': article.get("description", ""),
                            'content': article.get("content", ""),
                            'published_at': article["publishedAt"],
                        })
                
                total_articles += len(articles)
                print(f"âœ… ê·¸ë£¹ {i+1}: {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
                
                # API í˜¸ì¶œ ê°„ê²©
                if i < len(keywords) - 1:  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ ëŒ€ê¸°
                    import time
                    time.sleep(1)
                
            except Exception as e:
                print(f"âŒ í‚¤ì›Œë“œ ê·¸ë£¹ {i+1} ì‹¤íŒ¨: {str(e)}")
                continue
        
        # ìµœì¢… ê²°ê³¼
        result = hook.get_first("SELECT COUNT(*) FROM market_news")
        total_records = result[0] if result else 0
        print(f"âœ… ì™„ë£Œ. ì˜¤ëŠ˜ ìˆ˜ì§‘: {total_articles}ê°œ, ì´ ë ˆì½”ë“œ: {total_records}")
        
        return total_articles

    fetch_upsert = PythonOperator(
        task_id='fetch_and_upsert_market_news',
        python_callable=fetch_and_upsert_market_news,
    )

    # Task ì˜ì¡´ì„±
    create_table >> fetch_upsert