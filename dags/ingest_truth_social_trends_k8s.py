from datetime import datetime, timedelta
import subprocess
import json
import re
import os

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook

# ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "..", "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_truth_social_trends.sql"), encoding="utf-8") as f:
    UPSERT_TRENDS_SQL = f.read()

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': None,
    'retry_delay': timedelta(minutes=1),
}

def run_truthbrush_command(command_args):
    """Truthbrush ëª…ë ¹ì–´ ì‹¤í–‰"""
    try:
        cmd = ['truthbrush'] + command_args
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            return result.stdout
        else:
            raise Exception(f"Truthbrush ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
    except subprocess.TimeoutExpired:
        raise Exception("Truthbrush ëª…ë ¹ì–´ íƒ€ì„ì•„ì›ƒ")

def clean_html_content(content):
    """HTML íƒœê·¸ ì œê±°"""
    if not content:
        return ""
    return re.sub(r'<[^>]+>', '', content).strip()

def is_already_collected_recently(post_id):
    """ìµœê·¼ 8ì‹œê°„ ë‚´ ìˆ˜ì§‘ëœ í¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
    hook = PostgresHook(postgres_conn_id='postgres_default')
    query = """
    SELECT 1 FROM truth_social_trends 
    WHERE id = %s AND collected_at >= NOW() - INTERVAL '8 hours'
    """
    result = hook.get_first(query, parameters=[post_id])
    return result is not None

def parse_trend_data(raw_post, rank):
    """íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ë°ì´í„° ê°„ë‹¨ íŒŒì‹±"""
    account = raw_post.get('account', {})
    content = raw_post.get('content', '')
    created_at = raw_post.get('created_at', '').replace('Z', '+00:00') if raw_post.get('created_at') else None
    
    return {
        'id': raw_post.get('id'),
        'created_at': created_at,
        'username': account.get('username', ''),
        'account_id': account.get('id'),
        'display_name': account.get('display_name'),
        'content': content,
        'clean_content': clean_html_content(content),
        'language': raw_post.get('language'),
        'replies_count': raw_post.get('replies_count', 0),
        'reblogs_count': raw_post.get('reblogs_count', 0),
        'favourites_count': raw_post.get('favourites_count', 0),
        'upvotes_count': raw_post.get('upvotes_count', 0),
        'downvotes_count': raw_post.get('downvotes_count', 0),
        'url': raw_post.get('url'),
        'uri': raw_post.get('uri'),
        'tags': json.dumps(raw_post.get('tags', [])),
        'mentions': json.dumps(raw_post.get('mentions', [])),
        'visibility': raw_post.get('visibility', 'public'),
        'sensitive': raw_post.get('sensitive', False),
        'in_reply_to_id': raw_post.get('in_reply_to_id'),
        'trend_rank': rank,
        'trend_score': raw_post.get('favourites_count', 0)  # ë‹¨ìˆœíˆ ì¢‹ì•„ìš” ìˆ˜
    }

def fetch_trending_posts(**context):
    """íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ìˆ˜ì§‘"""
    print("ğŸ”¥ íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì¤‘...")
    
    output = run_truthbrush_command(['trends'])
    
    if not output.strip():
        raise Exception("ë¹ˆ ì‘ë‹µ ë°›ìŒ")
    
    # JSON íŒŒì‹±
    first_line = output.strip().split('\n')[0]
    trend_list = json.loads(first_line)
    
    if not isinstance(trend_list, list) or len(trend_list) == 0:
        raise Exception("ìœ íš¨í•œ íŠ¸ë Œë”© ë°ì´í„° ì—†ìŒ")
    
    # ì¤‘ë³µ ì²´í¬ ë° ë°ì´í„° íŒŒì‹±
    trends = []
    skipped_count = 0
    
    for rank, post_data in enumerate(trend_list[:20], 1):  # ìƒìœ„ 20ê°œë§Œ
        post_id = post_data.get('id')
        
        # ìµœê·¼ 8ì‹œê°„ ë‚´ ìˆ˜ì§‘ ì—¬ë¶€ í™•ì¸
        if is_already_collected_recently(post_id):
            print(f"â­ï¸ ì´ë¯¸ ìˆ˜ì§‘ëœ í¬ìŠ¤íŠ¸ ìŠ¤í‚µ: {post_id}")
            skipped_count += 1
            continue
        
        try:
            processed_trend = parse_trend_data(post_data, rank)
            trends.append(processed_trend)
        except Exception as e:
            print(f"âš ï¸ íŠ¸ë Œë”© íŒŒì‹± ì‹¤íŒ¨: {post_id} - {e}")
            continue
    
    if len(trends) == 0 and skipped_count > 0:
        print(f"âœ… ëª¨ë“  í¬ìŠ¤íŠ¸ê°€ ì´ë¯¸ ìˆ˜ì§‘ë¨ ({skipped_count}ê°œ ìŠ¤í‚µ)")
        context['ti'].xcom_push(key='trending_posts', value=[])
        return 0
    elif len(trends) == 0:
        raise Exception("íŒŒì‹±ëœ íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ì—†ìŒ")
    
    print(f"âœ… ìƒˆë¡œìš´ íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ {len(trends)}ê°œ ìˆ˜ì§‘ ({skipped_count}ê°œ ìŠ¤í‚µ)")
    context['ti'].xcom_push(key='trending_posts', value=trends)
    return len(trends)

def store_trends_to_db(**context):
    """íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ë¥¼ DBì— ì €ì¥"""
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    trends = context['ti'].xcom_pull(key='trending_posts')
    
    if not trends:
        print("â„¹ï¸ ì €ì¥í•  ìƒˆë¡œìš´ íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ì—†ìŒ")
        return 0
    
    success_count = 0
    for trend in trends:
        try:
            hook.run(UPSERT_TRENDS_SQL, parameters=trend)
            success_count += 1
        except Exception as e:
            print(f"âŒ íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ì €ì¥ ì‹¤íŒ¨: {trend.get('id', 'Unknown')} - {e}")
            raise  # í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨í•˜ë©´ ì „ì²´ ì‹¤íŒ¨
    
    print(f"âœ… íŠ¸ë Œë”© ì €ì¥ ì™„ë£Œ: {success_count}ê°œ")
    return success_count

# DAG ì •ì˜
with DAG(
    dag_id='ingest_truth_social_trends_k8s',
    default_args=default_args,
    schedule_interval='0 */8 * * *',  # 8ì‹œê°„ë§ˆë‹¤ (ê°œì„ )
    catchup=False,
    description='Truth Social íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ìˆ˜ì§‘',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['truth_social', 'trends', 'market_sentiment', 'k8s'],
) as dag:
    
    # í…Œì´ë¸” ìƒì„±
    create_table = PostgresOperator(
        task_id='create_truth_social_trends_table',
        postgres_conn_id='postgres_default',
        sql='create_truth_social_trends.sql',
    )
    
    # íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ìˆ˜ì§‘
    fetch_trends = PythonOperator(
        task_id='fetch_trending_posts',
        python_callable=fetch_trending_posts,
    )
    
    # DB ì €ì¥
    store_trends = PythonOperator(
        task_id='store_trends_to_db',
        python_callable=store_trends_to_db,
    )
    
    # Task ì˜ì¡´ì„±
    create_table >> fetch_trends >> store_trends