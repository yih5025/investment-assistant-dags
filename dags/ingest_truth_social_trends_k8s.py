from datetime import datetime, timedelta
import subprocess
import json
import re
import os

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook

# ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "..", "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_truth_social_trends.sql"), encoding="utf-8") as f:
    UPSERT_TRENDS_SQL = f.read()

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': None,
    'retry_delay': timedelta(minutes=1),
}

def run_truthbrush_command(command_args):
    """Truthbrush ëª…ë ¹ì–´ ì‹¤í–‰"""
    try:
        cmd = ['truthbrush'] + command_args
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            return result.stdout
        else:
            raise Exception(f"Truthbrush ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
    except subprocess.TimeoutExpired:
        raise Exception("Truthbrush ëª…ë ¹ì–´ íƒ€ì„ì•„ì›ƒ")

def clean_html_content(content):
    """HTML íƒœê·¸ ì œê±°"""
    if not content:
        return ""
    return re.sub(r'<[^>]+>', '', content).strip()

def calculate_trend_score(post_data):
    """íŠ¸ë Œë”© ì ìˆ˜ ê³„ì‚°"""
    replies = post_data.get('replies_count', 0)
    reblogs = post_data.get('reblogs_count', 0)
    favourites = post_data.get('favourites_count', 0)
    
    # ê°€ì¤‘ì¹˜ ì ìš©í•œ íŠ¸ë Œë”© ì ìˆ˜
    score = (favourites * 1.0) + (reblogs * 2.0) + (replies * 1.5)
    return round(score, 2)

def parse_trend_data(raw_post, rank):
    """íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ë°ì´í„° íŒŒì‹±"""
    account = raw_post.get('account', {})
    content = raw_post.get('content', '')
    
    created_at = raw_post.get('created_at', '').replace('Z', '+00:00') if raw_post.get('created_at') else None
    
    return {
        'id': raw_post.get('id'),
        'created_at': created_at,
        'username': account.get('username', ''),
        'account_id': account.get('id'),
        'display_name': account.get('display_name'),
        'content': content,
        'clean_content': clean_html_content(content),
        'language': raw_post.get('language'),
        'replies_count': raw_post.get('replies_count', 0),
        'reblogs_count': raw_post.get('reblogs_count', 0),
        'favourites_count': raw_post.get('favourites_count', 0),
        'upvotes_count': raw_post.get('upvotes_count', 0),
        'downvotes_count': raw_post.get('downvotes_count', 0),
        'url': raw_post.get('url'),
        'uri': raw_post.get('uri'),
        'tags': json.dumps(raw_post.get('tags', [])),
        'mentions': json.dumps(raw_post.get('mentions', [])),
        'visibility': raw_post.get('visibility', 'public'),
        'sensitive': raw_post.get('sensitive', False),
        'in_reply_to_id': raw_post.get('in_reply_to_id'),
        'trend_rank': rank,
        'trend_score': calculate_trend_score(raw_post)
    }

def fetch_trending_posts(**context):
    """íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ìˆ˜ì§‘"""
    print("ğŸ”¥ íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì¤‘...")
    
    try:
        output = run_truthbrush_command(['trends'])
        
        trends = []
        lines = output.strip().split('\n')
        
        # ì²« ë²ˆì§¸ ì¤„ì´ JSON ë°°ì—´ì¸ì§€ í™•ì¸
        if lines and lines[0].strip().startswith('['):
            try:
                trend_list = json.loads(lines[0])
                
                for rank, post_data in enumerate(trend_list[:20], 1):  # ìƒìœ„ 20ê°œë§Œ
                    processed_trend = parse_trend_data(post_data, rank)
                    trends.append(processed_trend)
                    
            except json.JSONDecodeError:
                print("âš ï¸ íŠ¸ë Œë”© ë°ì´í„° JSON íŒŒì‹± ì‹¤íŒ¨")
        else:
            # ë¼ì¸ë³„ë¡œ JSON ì²˜ë¦¬
            for rank, line in enumerate(lines[:20], 1):
                line = line.strip()
                if line and line.startswith('{'):
                    try:
                        post_data = json.loads(line)
                        processed_trend = parse_trend_data(post_data, rank)
                        trends.append(processed_trend)
                    except json.JSONDecodeError:
                        continue
        
        print(f"âœ… íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ {len(trends)}ê°œ ìˆ˜ì§‘")
        context['ti'].xcom_push(key='trending_posts', value=trends)
        return len(trends)
        
    except Exception as e:
        print(f"âŒ íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        context['ti'].xcom_push(key='trending_posts', value=[])
        return 0

def store_trends_to_db(**context):
    """íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ë¥¼ DBì— ì €ì¥"""
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    trends = context['ti'].xcom_pull(key='trending_posts') or []
    success_count = 0
    error_count = 0
    
    for trend in trends:
        try:
            hook.run(UPSERT_TRENDS_SQL, parameters=trend)
            success_count += 1
        except Exception as e:
            print(f"âŒ íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ì €ì¥ ì‹¤íŒ¨: {trend.get('id', 'Unknown')} - {e}")
            error_count += 1
    
    print(f"âœ… íŠ¸ë Œë”© ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")
    
    # í†µê³„ ì¡°íšŒ
    result = hook.get_first("SELECT COUNT(*) FROM truth_social_trends WHERE collected_at >= NOW() - INTERVAL '1 day'")
    total_trends = result[0] if result else 0
    print(f"ğŸ“Š ìµœê·¼ 24ì‹œê°„ íŠ¸ë Œë”© í¬ìŠ¤íŠ¸: {total_trends}ê°œ")
    
    return success_count

# DAG ì •ì˜
with DAG(
    dag_id='ingest_truth_social_trends_k8s',
    default_args=default_args,
    schedule_interval='0 */12 * * *',  # 12ì‹œê°„ë§ˆë‹¤
    catchup=False,
    description='Truth Social íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ìˆ˜ì§‘',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['truth_social', 'trends', 'market_sentiment', 'k8s'],
) as dag:
    
    # í…Œì´ë¸” ìƒì„±
    create_table = PostgresOperator(
        task_id='create_truth_social_trends_table',
        postgres_conn_id='postgres_default',
        sql='create_truth_social_trends.sql',
    )
    
    # íŠ¸ë Œë”© í¬ìŠ¤íŠ¸ ìˆ˜ì§‘
    fetch_trends = PythonOperator(
        task_id='fetch_trending_posts',
        python_callable=fetch_trending_posts,
    )
    
    # DB ì €ì¥
    store_trends = PythonOperator(
        task_id='store_trends_to_db',
        python_callable=store_trends_to_db,
    )
    
    # Task ì˜ì¡´ì„±
    create_table >> fetch_trends >> store_trends