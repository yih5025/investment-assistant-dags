#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import json
from datetime import datetime

# X API ì„¤ì •
BEARER_TOKEN = 'AAAAAAAAAAAAAAAAAAAAALeN0wEAAAAAeOv4ceQY%2B%2FziMshO7JeXxEnZG%2BM%3D2i0w1jJAHkU0OD1ry6WuNnLEC3TvgJZbH5Bg36vgGr5jRAoK8i'
ELON_MUSK_USER_ID = '44196397'  # @elonmuskì˜ USER_ID

def get_elon_recent_tweets():
    """ì¼ë¡  ë¨¸ìŠ¤í¬ì˜ ìµœì‹  íŠ¸ìœ— 10ê°œ ê°€ì ¸ì˜¤ê¸°"""
    
    print("ğŸš€ ì¼ë¡  ë¨¸ìŠ¤í¬ ìµœì‹  íŠ¸ìœ— 10ê°œ ìˆ˜ì§‘ ì‹œì‘...")
    
    # API ì—”ë“œí¬ì¸íŠ¸
    url = f"https://api.twitter.com/2/users/{ELON_MUSK_USER_ID}/tweets"
    
    # ìš”ì²­ íŒŒë¼ë¯¸í„° (ìµœëŒ€ 100ê°œê¹Œì§€ ê°€ëŠ¥)
    params = {
        "max_results": 10,  # 10ê°œ ê°€ì ¸ì˜¤ê¸° (1~100 ì‚¬ì´ ì¡°ì • ê°€ëŠ¥)
        
        # íˆ¬ì ë¶„ì„ì— í•„ìš”í•œ íŠ¸ìœ— í•„ë“œ
        "tweet.fields": ",".join([
            "created_at",           # ì‘ì„± ì‹œê°„
            "text",                 # íŠ¸ìœ— ë‚´ìš©  
            "public_metrics",       # ì¢‹ì•„ìš”, ë¦¬íŠ¸ìœ— ìˆ˜
            "context_annotations",  # ìë™ íƒœê·¸ (Tesla, SpaceX ë“±)
            "entities",             # í•´ì‹œíƒœê·¸, ë©˜ì…˜, URL
            "lang",                 # ì–¸ì–´
            "source"                # íŠ¸ìœ— ì¶œì²˜
        ]),
        
        # í™•ì¥ ì •ë³´
        "expansions": "author_id",
        
        # ì‚¬ìš©ì ì •ë³´
        "user.fields": ",".join([
            "name",
            "username", 
            "verified",
            "public_metrics"
        ])
    }
    
    # í—¤ë”
    headers = {
        "Authorization": f"Bearer {BEARER_TOKEN}",
        "User-Agent": "InvestmentAssistant-Test/1.0"
    }
    
    try:
        print("ğŸ“¡ X API í˜¸ì¶œ ì¤‘...")
        
        # API ìš”ì²­
        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        print(f"ğŸ“Š ì‘ë‹µ ì½”ë“œ: {response.status_code}")
        
        if response.status_code != 200:
            print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            print(f"ì—ëŸ¬ ì‘ë‹µ: {response.text}")
            return None
        
        # JSON íŒŒì‹±
        data = response.json()
        
        # ì‘ë‹µ ë°ì´í„° í™•ì¸
        if 'data' not in data or not data['data']:
            print("âš ï¸ ìµœê·¼ íŠ¸ìœ—ì´ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        print("âœ… íŠ¸ìœ— ìˆ˜ì§‘ ì„±ê³µ!")
        return data
        
    except requests.exceptions.Timeout:
        print("âŒ API ìš”ì²­ íƒ€ì„ì•„ì›ƒ (30ì´ˆ ì´ˆê³¼)")
        return None
    except requests.exceptions.RequestException as e:
        print(f"âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None

def analyze_tweet_data(data):
    """íŠ¸ìœ— ë°ì´í„° ë¶„ì„ ë° ì¶œë ¥"""
    
    if not data or 'data' not in data:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    tweets = data['data']  # ëª¨ë“  íŠ¸ìœ—ë“¤
    includes = data.get('includes', {})
    users = includes.get('users', [])
    
    print("\n" + "="*60)
    print(f"ğŸ“± ì¼ë¡  ë¨¸ìŠ¤í¬ ìµœì‹  íŠ¸ìœ— {len(tweets)}ê°œ ë¶„ì„")
    print("="*60)
    
    # ì‚¬ìš©ì ì •ë³´ (includesì—ì„œ)
    if users:
        user = users[0]
        print(f"ğŸ‘¤ ì‘ì„±ì ì •ë³´:")
        print(f"   ì´ë¦„: {user.get('name', 'N/A')}")
        print(f"   ì‚¬ìš©ìëª…: @{user.get('username', 'N/A')}")
        print(f"   ì¸ì¦: {'âœ… ì¸ì¦ë¨' if user.get('verified') else 'âŒ ë¯¸ì¸ì¦'}")
        
        # íŒ”ë¡œì›Œ ì •ë³´
        metrics = user.get('public_metrics', {})
        if metrics:
            print(f"   íŒ”ë¡œì›Œ: {metrics.get('followers_count', 0):,}ëª…")
            print(f"   íŒ”ë¡œì‰: {metrics.get('following_count', 0):,}ëª…")
    
    # ê° íŠ¸ìœ— ë¶„ì„
    investment_tweets = []
    total_engagement = 0
    
    for i, tweet in enumerate(tweets, 1):
        print(f"\nğŸ“ íŠ¸ìœ— #{i}")
        print("-" * 40)
        
        # ê¸°ë³¸ ì •ë³´
        print(f"ğŸ†” ID: {tweet['id']}")
        print(f"ğŸ“… ì‘ì„±: {tweet['created_at']}")
        print(f"ğŸŒ ì–¸ì–´: {tweet.get('lang', 'N/A')}")
        
        # íŠ¸ìœ— ë‚´ìš© (ê¸¸ë©´ ì¤„ì„)
        text = tweet['text']
        display_text = text if len(text) <= 100 else text[:100] + "..."
        print(f"ğŸ’¬ ë‚´ìš©: {display_text}")
        
        # ì°¸ì—¬ë„ ì§€í‘œ
        metrics = tweet.get('public_metrics', {})
        if metrics:
            likes = metrics.get('like_count', 0)
            retweets = metrics.get('retweet_count', 0)
            replies = metrics.get('reply_count', 0)
            quotes = metrics.get('quote_count', 0)
            
            engagement = likes + retweets + replies + quotes
            total_engagement += engagement
            
            print(f"ğŸ“Š ì°¸ì—¬ë„: â¤ï¸{likes:,} ğŸ”„{retweets:,} ğŸ’¬{replies:,} ğŸ“{quotes:,} (ì´ {engagement:,})")
        
        # íˆ¬ì ê´€ë ¨ì„± ë¶„ì„
        text_lower = text.lower()
        investment_keywords = [
            'tesla', 'tsla', 'spacex', 'stock', 'market', 'crypto', 'bitcoin', 
            'economy', 'price', 'share', 'investor', 'ipo', 'earnings', 'doge'
        ]
        
        found_keywords = [kw for kw in investment_keywords if kw in text_lower]
        
        if found_keywords:
            print(f"ğŸ’° íˆ¬ìí‚¤ì›Œë“œ: {', '.join(found_keywords)}")
            investment_tweets.append({
                'tweet_id': tweet['id'],
                'keywords': found_keywords,
                'engagement': engagement,
                'text': text
            })
    
    # ì „ì²´ í†µê³„
    print(f"\n" + "="*60)
    print(f"ğŸ“Š ì „ì²´ í†µê³„")
    print("="*60)
    print(f"ì´ íŠ¸ìœ—: {len(tweets)}ê°œ")
    print(f"íˆ¬ì ê´€ë ¨ íŠ¸ìœ—: {len(investment_tweets)}ê°œ ({len(investment_tweets)/len(tweets)*100:.1f}%)")
    print(f"ì´ ì°¸ì—¬ë„: {total_engagement:,}")
    print(f"í‰ê·  ì°¸ì—¬ë„: {total_engagement//len(tweets):,}/íŠ¸ìœ—")
    
    # íˆ¬ì ê´€ë ¨ë„ ë†’ì€ íŠ¸ìœ— TOP 3
    if investment_tweets:
        print(f"\nğŸ¯ íˆ¬ì ê´€ë ¨ ì¸ê¸° íŠ¸ìœ— TOP 3:")
        top_investment = sorted(investment_tweets, key=lambda x: x['engagement'], reverse=True)[:3]
        
        for i, tweet in enumerate(top_investment, 1):
            text_preview = tweet['text'][:80] + "..." if len(tweet['text']) > 80 else tweet['text']
            print(f"{i}. ì°¸ì—¬ë„ {tweet['engagement']:,} | í‚¤ì›Œë“œ: {', '.join(tweet['keywords'])}")
            print(f"   {text_preview}")
    
    # ì‹œì¥ ì˜í–¥ ì˜ˆìƒë„
    high_impact_count = len([t for t in investment_tweets if t['engagement'] > 50000])
    
    print(f"\nğŸš¨ ì‹œì¥ ì˜í–¥ ì˜ˆìƒ:")
    if high_impact_count > 0:
        print(f"   ë†’ì€ ì˜í–¥ íŠ¸ìœ—: {high_impact_count}ê°œ")
        print(f"   ğŸš¨ ì‹œì¥ ëª¨ë‹ˆí„°ë§ í•„ìš”")
    elif len(investment_tweets) > 0:
        print(f"   ì¤‘ê°„ ì˜í–¥ íŠ¸ìœ—: {len(investment_tweets)}ê°œ")
        print(f"   âš ï¸ ê´€ì‹¬ í•„ìš”")
    else:
        print(f"   â„¹ï¸ ì¼ë°˜ íŠ¸ìœ— - ë‚®ì€ ì˜í–¥")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ¯ ì¼ë¡  ë¨¸ìŠ¤í¬ íŠ¸ìœ— 10ê°œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    # í˜„ì¬ ì‹œê°„
    print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # íŠ¸ìœ— ìˆ˜ì§‘
    data = get_elon_recent_tweets()
    
    if data:
        # ì›ë³¸ JSONë„ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        print(f"\nğŸ“„ ì›ë³¸ JSON ì‘ë‹µ:")
        print("-" * 40)
        print(json.dumps(data, indent=2, ensure_ascii=False))
        
        # ìƒì„¸ ë¶„ì„
        analyze_tweet_data(data)
        
        print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - íŠ¸ìœ—ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    main()