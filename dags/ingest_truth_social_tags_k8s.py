from datetime import datetime, timedelta, date
import subprocess
import json
import os

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook

# ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "..", "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_truth_social_tags.sql"), encoding="utf-8") as f:
    UPSERT_TAGS_SQL = f.read()

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': None,
    'retry_delay': timedelta(minutes=1),
}

def run_truthbrush_command(command_args):
    """Truthbrush ëª…ë ¹ì–´ ì‹¤í–‰"""
    try:
        cmd = ['truthbrush'] + command_args
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            return result.stdout
        else:
            raise Exception(f"Truthbrush ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
    except subprocess.TimeoutExpired:
        raise Exception("Truthbrush ëª…ë ¹ì–´ íƒ€ì„ì•„ì›ƒ")

def classify_tag_market_relevance(tag_name):
    """í•´ì‹œíƒœê·¸ì˜ ì‹œì¥ ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°"""
    market_keywords = {
        # ë†’ì€ ê´€ë ¨ë„ (8-10ì )
        'economy': 10, 'stock': 10, 'market': 10, 'bitcoin': 10, 'crypto': 10,
        'inflation': 9, 'fed': 9, 'rates': 9, 'dollar': 9, 'trade': 9,
        'jobs': 8, 'gdp': 8, 'nasdaq': 8, 'sp500': 8, 'dow': 8,
        
        # ì¤‘ê°„ ê´€ë ¨ë„ (5-7ì )
        'energy': 7, 'oil': 7, 'gas': 7, 'gold': 6, 'silver': 6,
        'tech': 6, 'ai': 6, 'tesla': 6, 'apple': 6, 'google': 6,
        'banking': 5, 'finance': 5, 'investment': 5,
        
        # ë‚®ì€ ê´€ë ¨ë„ (1-4ì )
        'politics': 3, 'election': 3, 'congress': 2, 'senate': 2,
        'trump': 4, 'biden': 2, 'obama': 1
    }
    
    tag_lower = tag_name.lower()
    
    # ì§ì ‘ ë§¤ì¹­
    for keyword, score in market_keywords.items():
        if keyword in tag_lower:
            return score
    
    return 0  # ê´€ë ¨ ì—†ìŒ

def classify_tag_category(tag_name):
    """í•´ì‹œíƒœê·¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    categories = {
        'economy': ['economy', 'market', 'inflation', 'fed', 'rates', 'gdp', 'jobs'],
        'crypto': ['bitcoin', 'crypto', 'ethereum', 'blockchain', 'defi'],
        'stocks': ['stock', 'nasdaq', 'sp500', 'dow', 'tesla', 'apple', 'google'],
        'energy': ['energy', 'oil', 'gas', 'renewable'],
        'politics': ['trump', 'biden', 'obama', 'congress', 'senate', 'election'],
        'tech': ['ai', 'tech', 'innovation', 'startup']
    }
    
    tag_lower = tag_name.lower()
    
    for category, keywords in categories.items():
        if any(keyword in tag_lower for keyword in keywords):
            return category
    
    return 'general'

def calculate_trend_metrics(history_data):
    """íŠ¸ë Œë“œ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    if not history_data or len(history_data) < 2:
        return 0, 0, 0
    
    # ìµœê·¼ ì‚¬ìš©ëŸ‰ë“¤
    uses = [int(day.get('uses', 0)) for day in history_data]
    
    # ì„±ì¥ë¥  ê³„ì‚° (ì „ì¼ ëŒ€ë¹„)
    if len(uses) >= 2 and uses[1] > 0:
        growth_rate = ((uses[0] - uses[1]) / uses[1]) * 100
    else:
        growth_rate = 0
    
    # ì£¼ê°„ í‰ê· 
    weekly_average = sum(uses) / len(uses) if uses else 0
    
    # íŠ¸ë Œë“œ ì ìˆ˜ (ê°€ì¤‘í‰ê·  + ì„±ì¥ë¥ )
    if len(uses) >= 3:
        # ìµœê·¼ 3ì¼ ê°€ì¤‘í‰ê·  (ìµœì‹ ì¼ ê°€ì¤‘ì¹˜ ë†’ìŒ)
        weighted_avg = (uses[0] * 0.5 + uses[1] * 0.3 + uses[2] * 0.2) if len(uses) >= 3 else uses[0]
        trend_score = weighted_avg + (growth_rate * 0.1)
    else:
        trend_score = uses[0] if uses else 0
    
    return round(growth_rate, 2), round(weekly_average, 2), round(trend_score, 2)

def parse_tag_data(raw_tag):
    """í•´ì‹œíƒœê·¸ ë°ì´í„° íŒŒì‹±"""
    tag_name = raw_tag.get('name', '')
    history = raw_tag.get('history', [])
    
    # 7ì¼ê°„ ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
    day_uses = [0] * 7
    for i, day_data in enumerate(history[:7]):
        day_uses[i] = int(day_data.get('uses', 0))
    
    # ì´ ì‚¬ìš©ëŸ‰ ë° ê³„ì • ìˆ˜ (ì˜¤ëŠ˜)
    total_uses = day_uses[0] if day_uses else 0
    total_accounts = int(history[0].get('accounts', 0)) if history else 0
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    growth_rate, weekly_average, trend_score = calculate_trend_metrics(history)
    
    # ë¶„ë¥˜
    market_relevance = classify_tag_market_relevance(tag_name)
    tag_category = classify_tag_category(tag_name)
    
    return {
        'name': tag_name,
        'collected_date': date.today(),
        'url': raw_tag.get('url'),
        'total_uses': total_uses,
        'total_accounts': total_accounts,
        'recent_statuses_count': raw_tag.get('recent_statuses_count', 0),
        'history_data': json.dumps(history),
        'day_0_uses': day_uses[0] if len(day_uses) > 0 else 0,
        'day_1_uses': day_uses[1] if len(day_uses) > 1 else 0,
        'day_2_uses': day_uses[2] if len(day_uses) > 2 else 0,
        'day_3_uses': day_uses[3] if len(day_uses) > 3 else 0,
        'day_4_uses': day_uses[4] if len(day_uses) > 4 else 0,
        'day_5_uses': day_uses[5] if len(day_uses) > 5 else 0,
        'day_6_uses': day_uses[6] if len(day_uses) > 6 else 0,
        'trend_score': trend_score,
        'growth_rate': growth_rate,
        'weekly_average': weekly_average,
        'tag_category': tag_category,
        'market_relevance': market_relevance
    }

def fetch_trending_tags(**context):
    """íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ìˆ˜ì§‘"""
    print("ğŸ·ï¸ íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ìˆ˜ì§‘ ì¤‘...")
    
    try:
        output = run_truthbrush_command(['tags'])
        
        tags = []
        lines = output.strip().split('\n')
        
        # ì²« ë²ˆì§¸ ì¤„ì´ JSON ë°°ì—´ì¸ì§€ í™•ì¸
        if lines and lines[0].strip().startswith('['):
            try:
                tag_list = json.loads(lines[0])
                
                for tag_data in tag_list:
                    processed_tag = parse_tag_data(tag_data)
                    tags.append(processed_tag)
                    
            except json.JSONDecodeError:
                print("âš ï¸ í•´ì‹œíƒœê·¸ ë°ì´í„° JSON íŒŒì‹± ì‹¤íŒ¨")
        
        print(f"âœ… íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ {len(tags)}ê°œ ìˆ˜ì§‘")
        
        # ì‹œì¥ ê´€ë ¨ íƒœê·¸ í†µê³„
        market_tags = [tag for tag in tags if tag['market_relevance'] > 0]
        print(f"ğŸ“Š ì‹œì¥ ê´€ë ¨ íƒœê·¸: {len(market_tags)}ê°œ")
        
        context['ti'].xcom_push(key='trending_tags', value=tags)
        return len(tags)
        
    except Exception as e:
        print(f"âŒ íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        context['ti'].xcom_push(key='trending_tags', value=[])
        return 0

def store_tags_to_db(**context):
    """íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ë¥¼ DBì— ì €ì¥"""
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    tags = context['ti'].xcom_pull(key='trending_tags') or []
    success_count = 0
    error_count = 0
    
    for tag in tags:
        try:
            hook.run(UPSERT_TAGS_SQL, parameters=tag)
            success_count += 1
        except Exception as e:
            print(f"âŒ í•´ì‹œíƒœê·¸ ì €ì¥ ì‹¤íŒ¨: {tag.get('name', 'Unknown')} - {e}")
            error_count += 1
    
    print(f"âœ… í•´ì‹œíƒœê·¸ ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")
    
    # ì‹œì¥ ê´€ë ¨ íƒœê·¸ í†µê³„ ì¡°íšŒ
    market_query = """
    SELECT COUNT(*), AVG(market_relevance), MAX(total_uses)
    FROM truth_social_tags 
    WHERE collected_date = CURRENT_DATE AND market_relevance > 0
    """
    result = hook.get_first(market_query)
    if result:
        count, avg_relevance, max_uses = result
        print(f"ğŸ“Š ì˜¤ëŠ˜ ì‹œì¥ ê´€ë ¨ íƒœê·¸: {count}ê°œ, í‰ê·  ê´€ë ¨ë„: {avg_relevance:.1f}, ìµœëŒ€ ì‚¬ìš©ëŸ‰: {max_uses}")
    
    return success_count

# DAG ì •ì˜
with DAG(
    dag_id='ingest_truth_social_tags_k8s',
    default_args=default_args,
    schedule_interval='0 0 * * *',  # ë§¤ì¼ ìì •
    catchup=False,
    description='Truth Social íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ìˆ˜ì§‘',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['truth_social', 'hashtags', 'market_trends', 'k8s'],
) as dag:
    
    # í…Œì´ë¸” ìƒì„±
    create_table = PostgresOperator(
        task_id='create_truth_social_tags_table',
        postgres_conn_id='postgres_default',
        sql='create_truth_social_tags.sql',
    )
    
    # íŠ¸ë Œë”© í•´ì‹œíƒœê·¸ ìˆ˜ì§‘
    fetch_tags = PythonOperator(
        task_id='fetch_trending_tags',
        python_callable=fetch_trending_tags,
    )
    
    # DB ì €ì¥
    store_tags = PythonOperator(
        task_id='store_tags_to_db',
        python_callable=store_tags_to_db,
    )
    
    # Task ì˜ì¡´ì„±
    create_table >> fetch_tags >> store_tags