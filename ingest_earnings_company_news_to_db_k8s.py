from datetime import datetime, timedelta
import requests
import os
import time

from airflow import DAG
from airflow.models import Variable
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook

# í‘œì¤€ ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_company_news.sql"), encoding="utf-8") as f:
    UPSERT_SQL = f.read()

default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': None,
    'retry_delay': timedelta(minutes=1),
}

with DAG(
    dag_id='ingest_company_news_to_db_k8s',
    default_args=default_args,
    schedule_interval='0 9,15,21 * * *',
    catchup=False,
    description='Fetch news for trending stocks from top_gainers table with Rate Limit protection',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['company', 'news', 'finnhub', 'k8s', 'top-gainers', 'trending', 'rate-limit-safe'],
) as dag:

    create_table = PostgresOperator(
        task_id='create_company_news_table',
        postgres_conn_id='postgres_default',
        sql='create_company_news.sql',
    )

    def fetch_and_upsert_trending_news(**context):
        """ìµœì‹  íŠ¸ë Œë”© ì¢…ëª©(50ê°œ) ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì €ìž¥"""
        hook = PostgresHook(postgres_conn_id='postgres_default')
        api_key = Variable.get('FINNHUB_API_KEY')
        
        print(f"ðŸ”‘ API í‚¤ í™•ì¸: {api_key[:8]}...")
        
        # â­ í•µì‹¬: ìµœì‹  batch_idì˜ 50ê°œ ì¢…ëª© ëª¨ë‘ ì¡°íšŒ
        latest_batch_query = """
        SELECT 
            symbol, 
            category, 
            rank_position,
            change_percentage,
            volume,
            price
        FROM top_gainers 
        WHERE batch_id = (
            SELECT MAX(batch_id) FROM top_gainers
        )
        ORDER BY 
            CASE 
                WHEN category = 'top_gainers' THEN 1
                WHEN category = 'most_actively_traded' THEN 2  
                WHEN category = 'top_losers' THEN 3
                ELSE 4
            END,
            rank_position ASC
        """
        
        rows = hook.get_records(latest_batch_query)
        
        if not rows:
            print("âŒ top_gainers í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        # â­ ì •í™•í•œ 50ê°œ í™•ì¸
        if len(rows) != 50:
            print(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ë°ì´í„° ìˆ˜: {len(rows)}ê°œ (ì˜ˆìƒ: 50ê°œ)")
        
        # ë°°ì¹˜ ì •ë³´ ìƒì„¸ ì¶œë ¥
        batch_info_query = """
        SELECT 
            batch_id, 
            last_updated, 
            COUNT(*) as total_count,
            COUNT(CASE WHEN category = 'top_gainers' THEN 1 END) as gainers,
            COUNT(CASE WHEN category = 'most_actively_traded' THEN 1 END) as active,
            COUNT(CASE WHEN category = 'top_losers' THEN 1 END) as losers
        FROM top_gainers 
        WHERE batch_id = (SELECT MAX(batch_id) FROM top_gainers)
        GROUP BY batch_id, last_updated
        """
        
        batch_info = hook.get_first(batch_info_query)
        if batch_info:
            batch_id, last_updated, total, gainers, active, losers = batch_info
            print(f"ðŸ“Š ë°°ì¹˜ ì •ë³´: ID={batch_id}, ì—…ë°ì´íŠ¸={last_updated}")
            print(f"ðŸ“ˆ êµ¬ì„±: ìƒìŠ¹{gainers}ê°œ + í™œë°œ{active}ê°œ + í•˜ë½{losers}ê°œ = ì´{total}ê°œ")
            
            # â­ 50ê°œ í™•ì¸
            if total == 50:
                print("âœ… ì •í™•ížˆ 50ê°œ íŠ¸ë Œë”© ì¢…ëª© í™•ì¸ë¨")
            else:
                print(f"âš ï¸ ë¹„ì •ìƒì ì¸ ë°ì´í„° ìˆ˜: {total}ê°œ")
        
        success_count = 0
        error_count = 0 
        api_call_count = 0
        
        # ì‹œê°„ ë²”ìœ„ ì„¤ì • (ìµœê·¼ 24ì‹œê°„)
        from_date = (datetime.today() - timedelta(hours=24)).strftime("%Y-%m-%d")
        to_date = datetime.today().strftime("%Y-%m-%d")
        
        start_time = datetime.now()
        
        print(f"ðŸš€ 50ê°œ íŠ¸ë Œë”© ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œìž‘...")
        print(f"â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„: {50 * 3 / 60:.1f}ë¶„ (3ì´ˆ ë”œë ˆì´)")
        
        for i, row in enumerate(rows):
            symbol, category, rank_position, change_percentage, volume, price = row
            
            try:
                # â­ 50ê°œ ëª¨ë‘ 3ì´ˆ ë”œë ˆì´ (Rate Limit ë°©ì§€)
                if i > 0:
                    print(f"â³ 3ì´ˆ ëŒ€ê¸°... ({i+1}/50) - {symbol} ({category})")
                    time.sleep(3.0)
                
                call_start = datetime.now()
                
                # Finnhub API í˜¸ì¶œ
                resp = requests.get(
                    "https://finnhub.io/api/v1/company-news",
                    params={
                        "symbol": symbol,
                        "from": from_date,
                        "to": to_date,
                        "token": api_key,
                    },
                    timeout=30
                )
                
                api_call_count += 1
                call_duration = (datetime.now() - call_start).total_seconds()
                
                # Rate Limit ì²´í¬
                if resp.status_code == 429:
                    print(f"âš ï¸ Rate Limit: {symbol} ({category}) - 10ì´ˆ ì¶”ê°€ ëŒ€ê¸°")
                    time.sleep(10.0)
                    error_count += 1
                    continue
                
                resp.raise_for_status()
                articles = resp.json() or []
                
                # â­ íŠ¸ë Œë”© ì¢…ëª© ìƒì„¸ ì •ë³´ ë¡œê¹…
                print(f"ðŸ“° {symbol} ({category}, #{rank_position}): {len(articles)}ê°œ ê¸°ì‚¬ "
                      f"[{change_percentage} ë³€ë™, ${price}] ({call_duration:.1f}ì´ˆ)")
                
                # ê° ê¸°ì‚¬ ì €ìž¥
                article_success = 0
                for article in articles:
                    try:
                        if not article.get('url') or not article.get('datetime'):
                            continue
                        
                        published_at = datetime.fromtimestamp(article['datetime']).isoformat()
                        
                        # â­ íŠ¸ë Œë”© ì¹´í…Œê³ ë¦¬ ë©”íƒ€ë°ì´í„° í¬í•¨
                        content_with_meta = f"[{category}_rank_{rank_position}] {article.get('summary', '')}"
                        
                        hook.run(UPSERT_SQL, parameters={
                            'symbol': symbol,
                            'source': article.get('source', ''),
                            'url': article['url'],
                            'title': article.get('headline', ''),
                            'description': article.get('summary', ''),
                            'content': content_with_meta,  # ìˆœìœ„ ì •ë³´ê¹Œì§€ í¬í•¨
                            'published_at': published_at,
                        })
                        
                        article_success += 1
                        
                    except Exception as e:
                        print(f"âŒ ê¸°ì‚¬ ì €ìž¥ ì‹¤íŒ¨: {symbol} - {str(e)}")
                        continue
                
                success_count += article_success
                
                # â­ 50ê°œ ê¸°ì¤€ ì§„í–‰ë¥  í‘œì‹œ
                if (i + 1) % 10 == 0:  # 10ê°œë§ˆë‹¤ í‘œì‹œ
                    elapsed = (datetime.now() - start_time).total_seconds()
                    remaining = (50 - (i + 1)) * 3
                    progress_pct = ((i + 1) / 50) * 100
                    print(f"ðŸ“Š ì§„í–‰ë¥ : {i+1}/50 ({progress_pct:.1f}%) "
                          f"- ê²½ê³¼: {elapsed/60:.1f}ë¶„, ë‚¨ì€ì‹œê°„: {remaining/60:.1f}ë¶„")
                
            except requests.exceptions.HTTPError as e:
                if "429" in str(e):
                    print(f"ðŸš¨ HTTP 429: {symbol} ({category}) - 15ì´ˆ ëŒ€ê¸°")
                    time.sleep(15.0)
                else:
                    print(f"âŒ {symbol} ({category}) HTTP ì—ëŸ¬: {str(e)}")
                error_count += 1
                
            except requests.exceptions.Timeout:
                print(f"â±ï¸ {symbol} ({category}) íƒ€ìž„ì•„ì›ƒ - 5ì´ˆ ëŒ€ê¸° í›„ ê³„ì†")
                time.sleep(5.0)
                error_count += 1
                
            except Exception as e:
                print(f"âŒ {symbol} ({category}) API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
                error_count += 1
                continue
        
        # â­ 50ê°œ íŠ¸ë Œë”© ì¢…ëª© ìµœì¢… í†µê³„
        total_elapsed = (datetime.now() - start_time).total_seconds()
        print(f"\nðŸ 50ê°œ íŠ¸ë Œë”© ì¢…ëª© ì²˜ë¦¬ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {total_elapsed/60:.1f}ë¶„")
        print(f"ðŸ“ž ì´ API í˜¸ì¶œ: {api_call_count}íšŒ / 50íšŒ")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category_stats = {}
        for row in rows:
            category = row[1]
            category_stats[category] = category_stats.get(category, 0) + 1
        
        print(f"ðŸ“Š íŠ¸ë Œë”© ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬:")
        for category, count in category_stats.items():
            print(f"   - {category}: {count}ê°œ")
        
        print(f"âœ… ì €ìž¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")
        
        if api_call_count > 0:
            success_rate = (api_call_count - error_count) / api_call_count * 100
            print(f"ðŸ“ˆ API ì„±ê³µë¥ : {success_rate:.1f}%")
        
        # ìµœì¢… DB í†µê³„
        result = hook.get_first("SELECT COUNT(*) FROM company_news")
        total_records = result[0] if result else 0
        print(f"ðŸ“Š ì´ ê¸°ì—… ë‰´ìŠ¤ ë ˆì½”ë“œ ìˆ˜: {total_records}")
        
        # â­ ì˜¤ëŠ˜ íŠ¸ë Œë”© ë‰´ìŠ¤ ìƒì„¸ í†µê³„
        today_trending_query = """
        SELECT 
            COUNT(DISTINCT symbol) as unique_symbols, 
            COUNT(*) as total_articles,
            COUNT(CASE WHEN content LIKE '[top_gainers%' THEN 1 END) as gainer_articles,
            COUNT(CASE WHEN content LIKE '[most_actively_traded%' THEN 1 END) as active_articles,
            COUNT(CASE WHEN content LIKE '[top_losers%' THEN 1 END) as loser_articles
        FROM company_news 
        WHERE fetched_at >= CURRENT_DATE
        AND content LIKE '[%]%'
        """
        
        today_stats = hook.get_first(today_trending_query)
        if today_stats:
            unique_symbols, total_articles, gainer_arts, active_arts, loser_arts = today_stats
            print(f"ðŸ”¥ ì˜¤ëŠ˜ íŠ¸ë Œë”© ë‰´ìŠ¤ ìš”ì•½:")
            print(f"   - ì´ {unique_symbols}ê°œ ì¢…ëª©, {total_articles}ê°œ ê¸°ì‚¬")
            print(f"   - ìƒìŠ¹ì£¼ ë‰´ìŠ¤: {gainer_arts}ê°œ")
            print(f"   - í™œë°œì£¼ ë‰´ìŠ¤: {active_arts}ê°œ") 
            print(f"   - í•˜ë½ì£¼ ë‰´ìŠ¤: {loser_arts}ê°œ")
        
        return success_count

    fetch_upsert = PythonOperator(
        task_id='fetch_and_upsert_trending_news',
        python_callable=fetch_and_upsert_trending_news,
    )

    # Task ì˜ì¡´ì„±
    create_table >> fetch_upsert