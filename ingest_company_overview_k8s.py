# dags/ingest_company_overview_k8s.py
from datetime import datetime, timedelta
import os
import requests
from decimal import Decimal
import json
import time

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.models import Variable

# í‘œì¤€ ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_company_overview.sql"), encoding="utf-8") as f:
    UPSERT_SQL = f.read()

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': None,
    'retry_delay': timedelta(minutes=1),
}

def get_daily_symbols_batch(**context):
    """
    SP500 íšŒì‚¬ë“¤ì„ ì¼ë³„ë¡œ 50ê°œì”© ë¶„í• í•˜ì—¬ ì¡°íšŒ
    2ê°œ API í‚¤ë¡œ í•˜ë£¨ 50ê°œ â†’ 10ì¼ë¡œ 500ê°œ ì™„ë£Œ
    ì›”ë³„ batch_idë¡œ ë°ì´í„° íˆìŠ¤í† ë¦¬ ê´€ë¦¬
    """
    # ì‹¤í–‰ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë°°ì¹˜ ë²ˆí˜¸ ê³„ì‚° (1-10)
    execution_date = context['execution_date']
    
    # ì›”ì˜ ëª‡ ë²ˆì§¸ ì£¼ê¸°ì¸ì§€ ê³„ì‚° (1ì¼ì°¨, 2ì¼ì°¨... 10ì¼ì°¨)
    day_of_month = execution_date.day
    batch_number = ((day_of_month - 1) % 10) + 1  # 1~10 ìˆœí™˜
    
    print(f"ğŸ“… ì‹¤í–‰ ë‚ ì§œ: {execution_date.strftime('%Y-%m-%d')}")
    print(f"ğŸ”„ ë°°ì¹˜ ë²ˆí˜¸: {batch_number}/10")
    
    # DB ì—°ê²°
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    # ğŸ†• ì›”ë³„ batch_id ê³„ì‚° ë° ê´€ë¦¬
    current_month = execution_date.strftime('%Y-%m')
    print(f"ğŸ“† í˜„ì¬ ì—°ì›”: {current_month}")
    
    # ì´ë²ˆ ë‹¬ì˜ ê¸°ì¡´ ë°°ì¹˜ IDê°€ ìˆëŠ”ì§€ í™•ì¸
    existing_batch_query = """
    SELECT DISTINCT batch_id 
    FROM company_overview 
    WHERE TO_CHAR(created_at, 'YYYY-MM') = %s 
    LIMIT 1
    """
    
    existing_batch = hook.get_first(existing_batch_query, (current_month,))
    
    if existing_batch:
        # ê¸°ì¡´ ë°°ì¹˜ ID ì‚¬ìš© (ì´ë²ˆ ë‹¬ì— ì´ë¯¸ ìˆ˜ì§‘ ì¤‘)
        batch_id = existing_batch[0]
        print(f"ğŸ”„ ê¸°ì¡´ ë°°ì¹˜ ID ì‚¬ìš©: {batch_id} (ì´ë²ˆ ë‹¬ ê³„ì† ì§„í–‰)")
    else:
        # ìƒˆë¡œìš´ ë°°ì¹˜ ID ìƒì„± (ìƒˆë¡œìš´ ë‹¬ ì‹œì‘)
        max_batch_query = "SELECT COALESCE(MAX(batch_id), 0) FROM company_overview"
        max_batch_result = hook.get_first(max_batch_query)
        batch_id = (max_batch_result[0] if max_batch_result else 0) + 1
        print(f"ğŸ†• ìƒˆë¡œìš´ ë°°ì¹˜ ID ìƒì„±: {batch_id} (ìƒˆë¡œìš´ ë‹¬ ì‹œì‘)")
    
    # ì „ì²´ ì‹¬ë³¼ì„ alphabet ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¡°íšŒ
    query = """
    SELECT symbol, company_name 
    FROM sp500_companies 
    ORDER BY symbol ASC
    """
    
    all_symbols = hook.get_records(query)
    
    if not all_symbols:
        raise ValueError("âŒ SP500 companies í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
    
    print(f"ğŸ“Š ì „ì²´ SP500 ê¸°ì—… ìˆ˜: {len(all_symbols)}ê°œ")
    
    # 50ê°œì”© ë¶„í•  (ë°°ì¹˜ë³„)
    batch_size = 50
    start_idx = (batch_number - 1) * batch_size
    end_idx = start_idx + batch_size
    
    today_symbols = all_symbols[start_idx:end_idx]
    
    print(f"ğŸ¯ ì˜¤ëŠ˜ ìˆ˜ì§‘ ëŒ€ìƒ: {len(today_symbols)}ê°œ (ì¸ë±ìŠ¤ {start_idx}~{end_idx-1})")
    
    if not today_symbols:
        print("âš ï¸ ì˜¤ëŠ˜ ìˆ˜ì§‘í•  ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤ (ë°°ì¹˜ ë²”ìœ„ ì´ˆê³¼)")
        return {
            'batch_id': batch_id,  # ğŸ†• ì¶”ê°€
            'batch_number': batch_number,
            'symbols': [],
            'total_count': 0
        }
    
    # ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
    symbol_list = [row[0] for row in today_symbols]
    
    print(f"ğŸ“‹ ì˜¤ëŠ˜ì˜ ì‹¬ë³¼ë“¤: {symbol_list[:5]}{'...' if len(symbol_list) > 5 else ''}")
    print(f"ğŸ·ï¸ ì´ë²ˆ ë‹¬ ë°°ì¹˜ ID: {batch_id}")
    
    # XComì— ì €ì¥ (batch_id ì¶”ê°€)
    context['ti'].xcom_push(key='daily_symbols', value=symbol_list)
    context['ti'].xcom_push(key='batch_number', value=batch_number)
    context['ti'].xcom_push(key='batch_id', value=batch_id)  # ğŸ†• ì¶”ê°€
    
    return {
        'batch_id': batch_id,        # ğŸ†• ì¶”ê°€
        'batch_number': batch_number,
        'symbols': symbol_list,
        'total_count': len(symbol_list)
    }

def fetch_company_overview_data(**context):
    """
    Alpha Vantage Company Overview APIë¡œ íšŒì‚¬ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
    Rate Limit: 25 calls/day per API key â†’ 2ê°œ í‚¤ë¡œ 50 calls/day
    """
    # XComì—ì„œ ì˜¤ëŠ˜ì˜ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    symbol_list = context['ti'].xcom_pull(task_ids='get_daily_symbols', key='daily_symbols')
    batch_number = context['ti'].xcom_pull(task_ids='get_daily_symbols', key='batch_number')
    
    if not symbol_list:
        print("âš ï¸ ì˜¤ëŠ˜ ì²˜ë¦¬í•  ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤")
        return {'processed': 0, 'success': 0, 'errors': 0}
    
    # API í‚¤ ì„¤ì • (2ê°œ ë²ˆê°ˆì•„ ì‚¬ìš©)
    api_keys = [
        Variable.get('ALPHA_VANTAGE_API_KEY_3'),
        Variable.get('ALPHA_VANTAGE_API_KEY_4')  # ë‘ ë²ˆì§¸ í‚¤
    ]
    
    for key in api_keys:
        if not key:
            raise ValueError("âŒ Alpha Vantage API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    print(f"ğŸ”‘ API í‚¤ 2ê°œ í™•ì¸ ì™„ë£Œ")
    print(f"ğŸ“Š ë°°ì¹˜ {batch_number}: {len(symbol_list)}ê°œ ì‹¬ë³¼ ì²˜ë¦¬ ì‹œì‘")
    
    # ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥
    collected_data = []
    success_count = 0
    error_count = 0
    
    # API ìš”ì²­ URL
    base_url = "https://www.alphavantage.co/query"
    
    for i, symbol in enumerate(symbol_list):
        try:
            # API í‚¤ ë²ˆê°ˆì•„ ì‚¬ìš© (ì²« 25ê°œëŠ” key1, ë‚˜ë¨¸ì§€ 25ê°œëŠ” key2)
            api_key = api_keys[0] if i < 25 else api_keys[1]
            api_key_index = 1 if i < 25 else 2
            
            print(f"ğŸ” [{i+1}/{len(symbol_list)}] {symbol} ì²˜ë¦¬ ì¤‘... (APIí‚¤ {api_key_index})")
            
            # API ìš”ì²­ íŒŒë¼ë¯¸í„°
            params = {
                'function': 'OVERVIEW',
                'symbol': symbol,
                'apikey': api_key
            }
            
            # API í˜¸ì¶œ
            response = requests.get(base_url, params=params, timeout=30)
            response.raise_for_status()
            
            # Rate Limit ì²´í¬
            if 'Note' in response.text and 'API call frequency' in response.text:
                print(f"âš ï¸ API í˜¸ì¶œ ì œí•œ ë„ë‹¬: {symbol}")
                error_count += 1
                time.sleep(60)  # 1ë¶„ ëŒ€ê¸°
                continue
            
            # JSON íŒŒì‹±
            try:
                data = response.json()
            except json.JSONDecodeError as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {symbol} - {e}")
                error_count += 1
                continue
            
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
            if 'Error Message' in data:
                print(f"âŒ API ì˜¤ë¥˜: {symbol} - {data.get('Error Message')}")
                error_count += 1
                continue
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            if not data.get('Symbol') or not data.get('Name'):
                print(f"âŒ í•„ìˆ˜ ë°ì´í„° ëˆ„ë½: {symbol}")
                error_count += 1
                continue
            
            # ë°ì´í„° ì €ì¥
            collected_data.append({
                'symbol': symbol,
                'data': data,
                'api_key_used': api_key_index
            })
            
            success_count += 1
            print(f"âœ… {symbol} ìˆ˜ì§‘ ì™„ë£Œ - {data.get('Name', 'Unknown')}")
            
            # API Rate Limit ê³ ë ¤í•˜ì—¬ ë”œë ˆì´
            if i < len(symbol_list) - 1:  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´
                time.sleep(12)  # 12ì´ˆ ë”œë ˆì´ (í•˜ë£¨ 25íšŒ ì œí•œ ê³ ë ¤)
                
        except Exception as e:
            print(f"âŒ {symbol} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            error_count += 1
            continue
    
    print(f"ğŸ¯ ë°°ì¹˜ {batch_number} ìˆ˜ì§‘ ì™„ë£Œ:")
    print(f"   âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {error_count}ê°œ")
    print(f"   ğŸ“Š ì´ ì²˜ë¦¬: {len(symbol_list)}ê°œ")
    
    # XComì— ì €ì¥
    context['ti'].xcom_push(key='company_data', value=collected_data)
    
    return {
        'batch_number': batch_number,
        'processed': len(symbol_list),
        'success': success_count,
        'errors': error_count
    }

def process_and_store_overview_data(**context):
    """
    ìˆ˜ì§‘ëœ Company Overview ë°ì´í„°ë¥¼ PostgreSQLì— ì €ì¥
    """
    # XComì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    company_data = context['ti'].xcom_pull(task_ids='fetch_company_overview', key='company_data')
    batch_number = context['ti'].xcom_pull(task_ids='get_daily_symbols', key='batch_number')
    batch_id = context['ti'].xcom_pull(task_ids='get_daily_symbols', key='batch_id')
    
    if not company_data:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return {'stored': 0, 'success': 0, 'errors': 0}
    
    # DB ì—°ê²°
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    print(f"ğŸ’¾ ë°°ì¹˜ {batch_number}: {len(company_data)}ê°œ ë°ì´í„° ì €ì¥ ì‹œì‘")
    
    success_count = 0
    error_count = 0
    
    for item in company_data:
        try:
            symbol = item['symbol']
            data = item['data']
            
            # ìˆ«ì ë°ì´í„° ì•ˆì „í•˜ê²Œ ë³€í™˜
            def safe_decimal(value):
                try:
                    if value == 'None' or value is None or value == '-':
                        return None
                    return Decimal(str(value))
                except:
                    return None
            
            def safe_int(value):
                try:
                    if value == 'None' or value is None or value == '-':
                        return None
                    return int(float(str(value)))
                except:
                    return None
            
            def safe_str(value, max_length=None):
                try:
                    if value is None or value == 'None':
                        return None
                    result = str(value).strip()
                    if max_length and len(result) > max_length:
                        result = result[:max_length]
                    return result if result else None
                except:
                    return None
            
            # SQL íŒŒë¼ë¯¸í„° ì¤€ë¹„
            params = {
                'batch_id': batch_id,
                'symbol': symbol,
                'asset_type': safe_str(data.get('AssetType'), 50),
                'name': safe_str(data.get('Name'), 200),
                'description': safe_str(data.get('Description')),
                'cik': safe_str(data.get('CIK'), 20),
                'exchange': safe_str(data.get('Exchange'), 20),
                'currency': safe_str(data.get('Currency'), 10),
                'country': safe_str(data.get('Country'), 50),
                'sector': safe_str(data.get('Sector'), 100),
                'industry': safe_str(data.get('Industry'), 200),
                'address': safe_str(data.get('Address'), 300),
                'official_site': safe_str(data.get('OfficialSite'), 200),
                'fiscal_year_end': safe_str(data.get('FiscalYearEnd'), 20),
                'latest_quarter': safe_str(data.get('LatestQuarter'), 20),
                'market_capitalization': safe_int(data.get('MarketCapitalization')),
                'ebitda': safe_int(data.get('EBITDA')),
                'pe_ratio': safe_decimal(data.get('PERatio')),
                'peg_ratio': safe_decimal(data.get('PEGRatio')),
                'book_value': safe_decimal(data.get('BookValue')),
                'dividend_per_share': safe_decimal(data.get('DividendPerShare')),
                'dividend_yield': safe_decimal(data.get('DividendYield')),
                'eps': safe_decimal(data.get('EPS')),
                'revenue_per_share_ttm': safe_decimal(data.get('RevenuePerShareTTM')),
                'profit_margin': safe_decimal(data.get('ProfitMargin')),
                'operating_margin_ttm': safe_decimal(data.get('OperatingMarginTTM')),
                'return_on_assets_ttm': safe_decimal(data.get('ReturnOnAssetsTTM')),
                'return_on_equity_ttm': safe_decimal(data.get('ReturnOnEquityTTM')),
                'revenue_ttm': safe_int(data.get('RevenueTTM')),
                'gross_profit_ttm': safe_int(data.get('GrossProfitTTM')),
                'diluted_eps_ttm': safe_decimal(data.get('DilutedEPSTTM')),
                'quarterly_earnings_growth_yoy': safe_decimal(data.get('QuarterlyEarningsGrowthYOY')),
                'quarterly_revenue_growth_yoy': safe_decimal(data.get('QuarterlyRevenueGrowthYOY')),
                'analyst_target_price': safe_decimal(data.get('AnalystTargetPrice')),
                'trailing_pe': safe_decimal(data.get('TrailingPE')),
                'forward_pe': safe_decimal(data.get('ForwardPE')),
                'price_to_sales_ratio_ttm': safe_decimal(data.get('PriceToSalesRatioTTM')),
                'price_to_book_ratio': safe_decimal(data.get('PriceToBookRatio')),
                'ev_to_revenue': safe_decimal(data.get('EVToRevenue')),
                'ev_to_ebitda': safe_decimal(data.get('EVToEBITDA')),
                'beta': safe_decimal(data.get('Beta')),
                'week_52_high': safe_decimal(data.get('52WeekHigh')),
                'week_52_low': safe_decimal(data.get('52WeekLow')),
                'day_50_moving_average': safe_decimal(data.get('50DayMovingAverage')),
                'day_200_moving_average': safe_decimal(data.get('200DayMovingAverage')),
                'shares_outstanding': safe_int(data.get('SharesOutstanding')),
                'dividend_date': safe_str(data.get('DividendDate'), 20),
                'ex_dividend_date': safe_str(data.get('ExDividendDate'), 20)
            }
            
            # SQL ì‹¤í–‰
            hook.run(UPSERT_SQL, parameters=params)
            success_count += 1
            
            print(f"âœ… {symbol} ì €ì¥ ì™„ë£Œ - {params['name']}")
            
        except Exception as e:
            print(f"âŒ {symbol} ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            error_count += 1
            continue
    
    print(f"ğŸ’¾ ë°°ì¹˜ {batch_number} ì €ì¥ ì™„ë£Œ:")
    print(f"   âœ… ì„±ê³µ: {success_count}ê°œ") 
    print(f"   âŒ ì‹¤íŒ¨: {error_count}ê°œ")
    
    return {
        'batch_number': batch_number,
        'stored': len(company_data),
        'success': success_count,
        'errors': error_count
    }

# DAG ì •ì˜
with DAG(
    dag_id='ingest_company_overview_k8s',
    default_args=default_args,
    schedule_interval='0 2 * * *',  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ ì‹¤í–‰ (10ì¼ ì£¼ê¸°)
    catchup=False,
    description='Alpha Vantage APIë¡œ SP500 ê¸°ì—… ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ì¼ë³„ 50ê°œì”©)',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['sp500', 'alpha_vantage', 'company_overview', 'daily'],
) as dag:
    
    # 1. í…Œì´ë¸” ìƒì„±
    create_table = PostgresOperator(
        task_id='create_company_overview_table',
        postgres_conn_id='postgres_default',
        sql='create_company_overview.sql',
    )
    
    # 2. ì¼ë³„ ì‹¬ë³¼ ë°°ì¹˜ ì„ ì •
    get_symbols = PythonOperator(
        task_id='get_daily_symbols',
        python_callable=get_daily_symbols_batch,
    )
    
    # 3. Company Overview API ë°ì´í„° ìˆ˜ì§‘
    fetch_data = PythonOperator(
        task_id='fetch_company_overview',
        python_callable=fetch_company_overview_data,
    )
    
    # 4. ë°ì´í„° ê°€ê³µ ë° ì €ì¥
    process_data = PythonOperator(
        task_id='process_and_store_data',
        python_callable=process_and_store_overview_data,
    )
    
    # Task ì˜ì¡´ì„±
    create_table >> get_symbols >> fetch_data >> process_data