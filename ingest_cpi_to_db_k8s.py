from datetime import datetime, timedelta
import os
import requests

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.models import Variable

# SQL íŒŒì¼ ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_cpi.sql"), encoding="utf-8") as f:
    UPSERT_SQL = f.read()

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

def fetch_cpi_data(**context):
    """ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘"""
    api_key = Variable.get('ALPHA_VANTAGE_API_KEY_1')
    url = 'https://www.alphavantage.co/query'
    
    params = {
        'function': 'CPI',
        'interval': 'monthly',
        'datatype': 'json',
        'apikey': api_key
    }
    
    try:
        print("ğŸ“ˆ CPI ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        response = requests.get(url, params=params, timeout=60)
        response.raise_for_status()
        
        data = response.json()
        
        # API ì˜¤ë¥˜ í™•ì¸
        if 'Error Message' in data:
            raise ValueError(f"API ì˜¤ë¥˜: {data['Error Message']}")
            
        if 'Note' in data:
            raise ValueError(f"API ì œí•œ: {data['Note']}")
            
        if 'Information' in data:
            raise ValueError(f"API ì •ë³´: {data['Information']}")
        
        # ì‘ë‹µ êµ¬ì¡° í™•ì¸
        if 'data' not in data:
            raise ValueError(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ êµ¬ì¡°: {list(data.keys())}")
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = {
            'name': data.get('name', 'Consumer Price Index for all Urban Consumers'),
            'interval': data.get('interval', 'monthly'),
            'unit': data.get('unit', 'index 1982-1984=100')
        }
        
        # ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
        time_series = data.get('data', [])
        
        if not time_series:
            raise ValueError("CPI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ìµœê·¼ 24ê°œì›” ë°ì´í„°ë§Œ ìˆ˜ì§‘
        recent_data = time_series[:24] if len(time_series) > 24 else time_series
        
        print(f"âœ… CPI ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(recent_data)}ê°œ ë ˆì½”ë“œ")
        print(f"ğŸ“Š ë©”íƒ€ë°ì´í„°: {metadata}")
        print(f"ğŸ“… ë°ì´í„° ë²”ìœ„: {recent_data[-1]['date']} ~ {recent_data[0]['date']}")
        
        # XComì— ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥
        context['ti'].xcom_push(key='cpi_data', value=recent_data)
        context['ti'].xcom_push(key='metadata', value=metadata)
        
        return len(recent_data)
        
    except Exception as e:
        print(f"âŒ CPI ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        raise

def upsert_cpi_data(**context):
    """CPI ë°ì´í„° ì €ì¥"""
    # XComì—ì„œ ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    data = context['ti'].xcom_pull(task_ids='fetch_cpi_data', key='cpi_data')
    metadata = context['ti'].xcom_pull(task_ids='fetch_cpi_data', key='metadata')
    
    if not data:
        raise ValueError("ì´ì „ íƒœìŠ¤í¬ì—ì„œ CPI ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
    
    if not metadata:
        metadata = {
            'name': 'Consumer Price Index for all Urban Consumers',
            'interval': 'monthly', 
            'unit': 'index 1982-1984=100'
        }
    
    hook = PostgresHook(postgres_conn_id='postgres_default')
    success_count = 0
    error_count = 0
    
    print(f"ğŸš€ CPI ë°ì´í„° ì €ì¥ ì‹œì‘: {len(data)}ê°œ ë ˆì½”ë“œ")
    print(f"ğŸ“Š ë©”íƒ€ë°ì´í„°: {metadata}")
    
    for i, item in enumerate(data):
        try:
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            if not item.get('date') or not item.get('value'):
                print(f"âš ï¸ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {item}")
                error_count += 1
                continue
            
            # valueê°€ "." ë˜ëŠ” ë¹ˆ ê°’ì¸ ê²½ìš° ì²˜ë¦¬
            cpi_value = item['value']
            if cpi_value in ['.', '', 'null', None]:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ê°’: {item['date']} = {cpi_value}")
                cpi_value = None
            else:
                try:
                    cpi_value = float(cpi_value)
                except (ValueError, TypeError):
                    print(f"âš ï¸ ìˆ«ì ë³€í™˜ ì‹¤íŒ¨: {item['date']} = {cpi_value}")
                    cpi_value = None
            
            # ë°ì´í„° ë³€í™˜
            processed_item = {
                'date': item['date'],
                'cpi_value': cpi_value,
                'interval_type': metadata['interval'],
                'unit': metadata['unit'],
                'name': metadata['name']
            }
            
            # SQL ì‹¤í–‰
            hook.run(UPSERT_SQL, parameters=processed_item)
            success_count += 1
            
            # ì§„í–‰ë¥  í‘œì‹œ (10ê°œë§ˆë‹¤)
            if (i + 1) % 10 == 0:
                print(f"ğŸ“Š ì§„í–‰ë¥ : {i+1}/{len(data)}")
                
        except Exception as e:
            print(f"âŒ ë ˆì½”ë“œ ì €ì¥ ì‹¤íŒ¨: {item.get('date', 'Unknown')} - {str(e)}")
            error_count += 1
            continue
    
    # ìµœì¢… í†µê³„
    print(f"âœ… CPI ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")
    
    # ì „ì²´ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
    result = hook.get_first("SELECT COUNT(*) FROM cpi")
    total_records = result[0] if result else 0
    print(f"ğŸ“Š ì´ ë ˆì½”ë“œ ìˆ˜: {total_records}")
    
    # ìµœì‹  5ê°œ ë ˆì½”ë“œ í™•ì¸
    latest_records = hook.get_records(
        "SELECT date, cpi_value FROM cpi ORDER BY date DESC LIMIT 5"
    )
    print(f"ğŸ“… ìµœì‹  5ê°œ ë ˆì½”ë“œ:")
    for record in latest_records:
        print(f"   {record[0]}: {record[1]}")
    
    return success_count

# DAG ì •ì˜
with DAG(
    dag_id='ingest_cpi_to_db',
    default_args=default_args,
    schedule_interval='@monthly',  # ì›” 1íšŒ ì‹¤í–‰
    catchup=False,
    description='Alpha Vantage CPI ë°ì´í„° ìˆ˜ì§‘',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['economic_indicators', 'alpha_vantage', 'cpi', 'inflation'],
) as dag:
    
    # í…Œì´ë¸” ìƒì„±
    create_table = PostgresOperator(
        task_id='create_cpi_table',
        postgres_conn_id='postgres_default',
        sql='create_cpi.sql',
    )
    
    # ë°ì´í„° ìˆ˜ì§‘
    fetch_data = PythonOperator(
        task_id='fetch_cpi_data',
        python_callable=fetch_cpi_data,
    )
    
    # ë°ì´í„° ì €ì¥
    upsert_data = PythonOperator(
        task_id='upsert_cpi_data',
        python_callable=upsert_cpi_data,
    )
    
    # Task ì˜ì¡´ì„±
    create_table >> fetch_data >> upsert_data