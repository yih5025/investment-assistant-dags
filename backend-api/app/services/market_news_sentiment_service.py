from sqlalchemy.orm import Session
from sqlalchemy import func, and_, desc, asc, text
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime, timedelta
import json

from app.models.market_news_sentiment_model import MarketNewsSentiment

class MarketNewsSentimentService:
    """
    ÏãúÏû• Îâ¥Ïä§ Í∞êÏÑ± Î∂ÑÏÑù ÎπÑÏ¶àÎãàÏä§ Î°úÏßÅÏùÑ Ï≤òÎ¶¨ÌïòÎäî ÏÑúÎπÑÏä§ ÌÅ¥ÎûòÏä§
    
    Ï£ºÏöî Í∏∞Îä•:
    1. JSONB Îç∞Ïù¥ÌÑ∞ ÌååÏã± (ticker_sentiment, topics)
    2. Í∞êÏÑ± Ï†êÏàò Í∏∞Î∞ò Î∂ÑÏÑù Î∞è Îû≠ÌÇπ
    3. Ï£ºÏ†úÎ≥Ñ/Ìã∞Ïª§Î≥Ñ ÌïÑÌÑ∞ÎßÅ
    4. ÌÅ¨Î°úÏä§ Î∂ÑÏÑù (Ï£ºÏ†ú‚ÜîÌã∞Ïª§ Í¥ÄÍ≥Ñ)
    """
    
    def __init__(self, db: Session):
        self.db = db
    
    # =========================================================================
    # JSONB Îç∞Ïù¥ÌÑ∞ ÌååÏã± Ïú†Ìã∏Î¶¨Ìã∞ Î©îÏÑúÎìú
    # =========================================================================
    
    def parse_ticker_sentiment(self, ticker_sentiment_json: Any) -> List[Dict]:
        """
        ticker_sentiment JSONB Îç∞Ïù¥ÌÑ∞Î•º ÌååÏã±Ìï©ÎãàÎã§.
        
        Args:
            ticker_sentiment_json: JSONB Îç∞Ïù¥ÌÑ∞ (Î¶¨Ïä§Ìä∏ ÌòïÌÉú)
            
        Returns:
            List[Dict]: ÌååÏã±Îêú Ìã∞Ïª§ Í∞êÏÑ± Îç∞Ïù¥ÌÑ∞
        """
        if not ticker_sentiment_json:
            return []
            
        try:
            if isinstance(ticker_sentiment_json, str):
                data = json.loads(ticker_sentiment_json)
            else:
                data = ticker_sentiment_json
                
            result = []
            for item in data:
                result.append({
                    "ticker": item.get("ticker", ""),
                    "relevance_score": float(item.get("relevance_score", 0)),
                    "ticker_sentiment_label": item.get("ticker_sentiment_label", "Neutral"),
                    "ticker_sentiment_score": float(item.get("ticker_sentiment_score", 0))
                })
            return result
        except (json.JSONDecodeError, TypeError, KeyError):
            return []
    
    def parse_topics(self, topics_json: Any) -> List[Dict]:
        """
        topics JSONB Îç∞Ïù¥ÌÑ∞Î•º ÌååÏã±Ìï©ÎãàÎã§.
        
        Args:
            topics_json: JSONB Îç∞Ïù¥ÌÑ∞ (Î¶¨Ïä§Ìä∏ ÌòïÌÉú)
            
        Returns:
            List[Dict]: ÌååÏã±Îêú Ï£ºÏ†ú Í¥ÄÎ†®ÎèÑ Îç∞Ïù¥ÌÑ∞
        """
        if not topics_json:
            return []
            
        try:
            if isinstance(topics_json, str):
                data = json.loads(topics_json)
            else:
                data = topics_json
                
            result = []
            for item in data:
                result.append({
                    "topic": item.get("topic", ""),
                    "relevance_score": float(item.get("relevance_score", 0))
                })
            return result
        except (json.JSONDecodeError, TypeError, KeyError):
            return []
    
    def enrich_news_with_jsonb_data(self, news_items: List[MarketNewsSentiment]) -> List[Dict]:
        """
        Îâ¥Ïä§ ÏïÑÏù¥ÌÖúÏóê JSONB Îç∞Ïù¥ÌÑ∞Î•º ÌååÏã±ÌïòÏó¨ Ï∂îÍ∞ÄÌï©ÎãàÎã§.
        
        Args:
            news_items: ÏõêÎ≥∏ Îâ¥Ïä§ Îç∞Ïù¥ÌÑ∞
            
        Returns:
            List[Dict]: JSONB Îç∞Ïù¥ÌÑ∞Í∞Ä ÌååÏã±Îêú Îâ¥Ïä§ Îç∞Ïù¥ÌÑ∞
        """
        enriched_news = []
        
        for news in news_items:
            news_dict = {
                "batch_id": news.batch_id,
                "url": news.url,
                "title": news.title,
                "time_published": news.time_published,
                "authors": news.authors,
                "summary": news.summary,
                "source": news.source,
                "overall_sentiment_score": float(news.overall_sentiment_score) if news.overall_sentiment_score else None,
                "overall_sentiment_label": news.overall_sentiment_label,
                "query_type": news.query_type,
                "query_params": news.query_params,
                "created_at": news.created_at,
                
                # Í∞êÏÑ± Ìï¥ÏÑù Ï∂îÍ∞Ä
                "sentiment_interpretation": news.sentiment_interpretation,
                "sentiment_emoji": news.sentiment_emoji,
                
                # JSONB Îç∞Ïù¥ÌÑ∞ ÌååÏã±
                "related_tickers": self.parse_ticker_sentiment(news.ticker_sentiment),
                "related_topics": self.parse_topics(news.topics)
            }
            enriched_news.append(news_dict)
            
        return enriched_news
    
    # =========================================================================
    # Í∏∞Î≥∏ Îâ¥Ïä§ Ï°∞Ìöå Î©îÏÑúÎìú
    # =========================================================================
    
    def get_latest_batch_id(self) -> Optional[int]:
        """ÏµúÏã† Î∞∞Ïπò IDÎ•º Ï°∞ÌöåÌï©ÎãàÎã§."""
        result = self.db.query(func.max(MarketNewsSentiment.batch_id)).scalar()
        return result if result else None
    
    def get_batch_info(self) -> Dict[str, Any]:
        """Î∞∞Ïπò Ï†ïÎ≥¥Î•º Ï°∞ÌöåÌï©ÎãàÎã§."""
        latest_batch_id = self.get_latest_batch_id()
        
        # Ï¥ù Î∞∞Ïπò Ïàò Ï°∞Ìöå
        total_batches = self.db.query(func.count(func.distinct(MarketNewsSentiment.batch_id))).scalar()
        
        # ÏµúÏã† Î∞∞ÏπòÏùò ÏàòÏßë ÎÇ†Ïßú Ï°∞Ìöå
        collection_date = "Ïïå Ïàò ÏóÜÏùå"
        if latest_batch_id:
            latest_news = (self.db.query(MarketNewsSentiment)
                          .filter(MarketNewsSentiment.batch_id == latest_batch_id)
                          .first())
            if latest_news and latest_news.created_at:
                collection_date = latest_news.created_at.strftime("%Y-%m-%d")
        
        return {
            "latest_batch_id": latest_batch_id or 0,
            "collection_date": collection_date,
            "total_batches": total_batches or 0
        }
    
    def get_news_list(self, days: int = 7, limit: int = 20, offset: int = 0,
                     min_sentiment: Optional[float] = None, max_sentiment: Optional[float] = None,
                     sentiment_labels: Optional[List[str]] = None,
                     sort_by: str = "time_published", order: str = "desc") -> Tuple[List[Dict], int]:
        """
        Îâ¥Ïä§ Î™©Î°ùÏùÑ Ï°∞ÌöåÌï©ÎãàÎã§.
        
        Args:
            days: ÏµúÍ∑º NÏùº Îç∞Ïù¥ÌÑ∞
            limit: Í≤∞Í≥º Í∞úÏàò Ï†úÌïú
            offset: ÌéòÏù¥Ïßï Ïò§ÌîÑÏÖã
            min_sentiment: ÏµúÏÜå Í∞êÏÑ± Ï†êÏàò
            max_sentiment: ÏµúÎåÄ Í∞êÏÑ± Ï†êÏàò
            sentiment_labels: Í∞êÏÑ± ÎùºÎ≤® ÌïÑÌÑ∞
            sort_by: Ï†ïÎ†¨ Í∏∞Ï§Ä
            order: Ï†ïÎ†¨ ÏàúÏÑú
            
        Returns:
            Tuple[news_list, total_count]: Îâ¥Ïä§ Î™©Î°ùÍ≥º Ï¥ù Í∞úÏàò
        """
        # Í∏∞Î≥∏ ÏøºÎ¶¨
        query = self.db.query(MarketNewsSentiment)
        
        # ÎÇ†Ïßú ÌïÑÌÑ∞
        cutoff_date = datetime.now() - timedelta(days=days)
        query = query.filter(MarketNewsSentiment.time_published >= cutoff_date)
        
        # Í∞êÏÑ± Ï†êÏàò ÌïÑÌÑ∞
        if min_sentiment is not None:
            query = query.filter(MarketNewsSentiment.overall_sentiment_score >= min_sentiment)
        if max_sentiment is not None:
            query = query.filter(MarketNewsSentiment.overall_sentiment_score <= max_sentiment)
        
        # Í∞êÏÑ± ÎùºÎ≤® ÌïÑÌÑ∞
        if sentiment_labels:
            query = query.filter(MarketNewsSentiment.overall_sentiment_label.in_(sentiment_labels))
        
        # Ï¥ù Í∞úÏàò Í≥ÑÏÇ∞
        total_count = query.count()
        
        # Ï†ïÎ†¨
        if sort_by == "sentiment_score":
            sort_column = MarketNewsSentiment.overall_sentiment_score
        elif sort_by == "time_published":
            sort_column = MarketNewsSentiment.time_published
        else:
            sort_column = MarketNewsSentiment.time_published
        
        if order == "desc":
            query = query.order_by(desc(sort_column))
        else:
            query = query.order_by(asc(sort_column))
        
        # ÌéòÏù¥Ïßï
        news_items = query.limit(limit).offset(offset).all()
        
        # JSONB Îç∞Ïù¥ÌÑ∞ ÌååÏã±ÌïòÏó¨ Î∞òÌôò
        enriched_news = self.enrich_news_with_jsonb_data(news_items)
        
        return enriched_news, total_count
    
    def get_news_by_batch(self, batch_id: int, limit: int = 20, offset: int = 0) -> List[Dict]:
        """ÌäπÏ†ï Î∞∞ÏπòÏùò Îâ¥Ïä§Î•º Ï°∞ÌöåÌï©ÎãàÎã§."""
        news_items = (self.db.query(MarketNewsSentiment)
                     .filter(MarketNewsSentiment.batch_id == batch_id)
                     .order_by(desc(MarketNewsSentiment.time_published))
                     .limit(limit)
                     .offset(offset)
                     .all())
        
        return self.enrich_news_with_jsonb_data(news_items)
    
    # =========================================================================
    # Topic & Ticker Í¥ÄÎ†® Î©îÏÑúÎìú
    # =========================================================================
    
    def get_all_topics(self) -> List[str]:
        """Î™®Îì† Ï£ºÏ†ú Î™©Î°ùÏùÑ Ï°∞ÌöåÌï©ÎãàÎã§."""
        # PostgreSQL JSONB ÏøºÎ¶¨Î°ú Î™®Îì† topic Ï∂îÏ∂ú
        query = text("""
            SELECT DISTINCT jsonb_array_elements(topics)->>'topic' as topic
            FROM market_news_sentiment 
            WHERE topics IS NOT NULL
            ORDER BY topic
        """)
        
        result = self.db.execute(query).fetchall()
        return [row[0] for row in result if row[0]]
    
    def get_all_tickers(self) -> List[str]:
        """Î™®Îì† Ìã∞Ïª§ Î™©Î°ùÏùÑ Ï°∞ÌöåÌï©ÎãàÎã§."""
        # PostgreSQL JSONB ÏøºÎ¶¨Î°ú Î™®Îì† ticker Ï∂îÏ∂ú
        query = text("""
            SELECT DISTINCT jsonb_array_elements(ticker_sentiment)->>'ticker' as ticker
            FROM market_news_sentiment 
            WHERE ticker_sentiment IS NOT NULL
            ORDER BY ticker
        """)
        
        result = self.db.execute(query).fetchall()
        return [row[0] for row in result if row[0]]
    
    def get_news_by_topic(self, topic: str, days: int = 7, limit: int = 20, offset: int = 0) -> Tuple[List[Dict], Dict]:
        """ÌäπÏ†ï Ï£ºÏ†úÏùò Îâ¥Ïä§Î•º Ï°∞ÌöåÌï©ÎãàÎã§."""
        # PostgreSQL JSONB Ïó∞ÏÇ∞Ïûê ÏÇ¨Ïö©ÌïòÏó¨ ÌäπÏ†ï Ï£ºÏ†ú ÌïÑÌÑ∞ÎßÅ
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            SELECT * FROM market_news_sentiment 
            WHERE topics @> :topic_filter
            AND time_published >= :cutoff_date
            ORDER BY time_published DESC
            LIMIT :limit OFFSET :offset
        """)
        
        topic_filter = json.dumps([{"topic": topic}])
        result = self.db.execute(query, {
            "topic_filter": topic_filter,
            "cutoff_date": cutoff_date,
            "limit": limit,
            "offset": offset
        }).fetchall()
        
        # Í≤∞Í≥ºÎ•º MarketNewsSentiment Í∞ùÏ≤¥Î°ú Î≥ÄÌôò
        news_items = []
        for row in result:
            news_item = MarketNewsSentiment()
            for i, column in enumerate(MarketNewsSentiment.__table__.columns):
                setattr(news_item, column.name, row[i])
            news_items.append(news_item)
        
        enriched_news = self.enrich_news_with_jsonb_data(news_items)
        
        # Ï£ºÏ†úÎ≥Ñ Í∞êÏÑ± ÏöîÏïΩ Í≥ÑÏÇ∞
        topic_summary = self.calculate_topic_sentiment_summary(topic, days)
        
        return enriched_news, topic_summary
    
    def get_news_by_ticker(self, ticker: str, days: int = 7, limit: int = 20, offset: int = 0) -> Tuple[List[Dict], Dict]:
        """ÌäπÏ†ï Ìã∞Ïª§Ïùò Îâ¥Ïä§Î•º Ï°∞ÌöåÌï©ÎãàÎã§."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            SELECT * FROM market_news_sentiment 
            WHERE ticker_sentiment @> :ticker_filter
            AND time_published >= :cutoff_date
            ORDER BY time_published DESC
            LIMIT :limit OFFSET :offset
        """)
        
        ticker_filter = json.dumps([{"ticker": ticker}])
        result = self.db.execute(query, {
            "ticker_filter": ticker_filter,
            "cutoff_date": cutoff_date,
            "limit": limit,
            "offset": offset
        }).fetchall()
        
        # Í≤∞Í≥ºÎ•º MarketNewsSentiment Í∞ùÏ≤¥Î°ú Î≥ÄÌôò
        news_items = []
        for row in result:
            news_item = MarketNewsSentiment()
            for i, column in enumerate(MarketNewsSentiment.__table__.columns):
                setattr(news_item, column.name, row[i])
            news_items.append(news_item)
        
        enriched_news = self.enrich_news_with_jsonb_data(news_items)
        
        # Ìã∞Ïª§Î≥Ñ Í∞êÏÑ± ÏöîÏïΩ Í≥ÑÏÇ∞
        ticker_summary = self.calculate_ticker_sentiment_summary(ticker, days)
        
        return enriched_news, ticker_summary
    
    # =========================================================================
    # Í∞êÏÑ± Î∂ÑÏÑù Î∞è Îû≠ÌÇπ Î©îÏÑúÎìú
    # =========================================================================
    
    def get_sentiment_filtered_news(self, sentiment_type: str, days: int = 7, 
                                   limit: int = 20, offset: int = 0) -> List[Dict]:
        """Í∞êÏÑ±Î≥ÑÎ°ú ÌïÑÌÑ∞ÎßÅÎêú Îâ¥Ïä§Î•º Ï°∞ÌöåÌï©ÎãàÎã§."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = self.db.query(MarketNewsSentiment).filter(
            MarketNewsSentiment.time_published >= cutoff_date
        )
        
        # Í∞êÏÑ± ÌÉÄÏûÖÎ≥Ñ ÌïÑÌÑ∞ÎßÅ
        if sentiment_type == "bullish":
            query = query.filter(MarketNewsSentiment.overall_sentiment_score > 0.1)
        elif sentiment_type == "bearish":
            query = query.filter(MarketNewsSentiment.overall_sentiment_score < -0.1)
        elif sentiment_type == "neutral":
            query = query.filter(
                and_(
                    MarketNewsSentiment.overall_sentiment_score >= -0.1,
                    MarketNewsSentiment.overall_sentiment_score <= 0.1
                )
            )
        
        news_items = (query.order_by(desc(MarketNewsSentiment.time_published))
                     .limit(limit)
                     .offset(offset)
                     .all())
        
        return self.enrich_news_with_jsonb_data(news_items)
    
    def calculate_topic_sentiment_ranking(self, days: int = 7, top_count: int = 10,
                                        bottom_count: int = 10, min_mentions: int = 2) -> Tuple[List[Dict], List[Dict]]:
        """Ï£ºÏ†úÎ≥Ñ Í∞êÏÑ± Îû≠ÌÇπÏùÑ Í≥ÑÏÇ∞Ìï©ÎãàÎã§."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # PostgreSQL JSONB ÏßëÍ≥Ñ ÏøºÎ¶¨
        query = text("""
            WITH topic_stats AS (
                SELECT 
                    jsonb_array_elements(topics)->>'topic' as topic,
                    AVG(overall_sentiment_score) as avg_sentiment,
                    COUNT(*) as news_count,
                    AVG((jsonb_array_elements(topics)->>'relevance_score')::float) as avg_relevance
                FROM market_news_sentiment 
                WHERE time_published >= :cutoff_date
                AND topics IS NOT NULL
                AND overall_sentiment_score IS NOT NULL
                GROUP BY jsonb_array_elements(topics)->>'topic'
                HAVING COUNT(*) >= :min_mentions
            )
            SELECT topic, avg_sentiment, news_count, avg_relevance
            FROM topic_stats
            ORDER BY avg_sentiment DESC
        """)
        
        result = self.db.execute(query, {
            "cutoff_date": cutoff_date,
            "min_mentions": min_mentions
        }).fetchall()
        
        # Í≤∞Í≥º Ï≤òÎ¶¨
        all_topics = []
        for row in result:
            topic, avg_sentiment, news_count, avg_relevance = row
            
            # Í∞êÏÑ± ÎùºÎ≤® Í≤∞Ï†ï
            sentiment_label, sentiment_emoji = self._get_sentiment_label_and_emoji(avg_sentiment)
            
            # Í¥ÄÎ†® Ìã∞Ïª§ Ï°∞Ìöå
            related_tickers = self._get_tickers_by_topic(topic, days)
            
            topic_data = {
                "topic": topic,
                "avg_sentiment_score": float(avg_sentiment),
                "news_count": news_count,
                "sentiment_label": sentiment_label,
                "sentiment_emoji": sentiment_emoji,
                "trend": "ÏÉÅÏäπ" if avg_sentiment > 0.05 else "ÌïòÎùΩ" if avg_sentiment < -0.05 else "ÏïàÏ†ï",
                "related_tickers": related_tickers[:5]  # ÏÉÅÏúÑ 5Í∞úÎßå
            }
            all_topics.append(topic_data)
        
        # Hot & Cold Î∂ÑÎ¶¨
        hot_topics = all_topics[:top_count]
        cold_topics = all_topics[-bottom_count:] if len(all_topics) > bottom_count else []
        cold_topics.reverse()  # Í∞ÄÏû• Î∂ÄÏ†ïÏ†ÅÏù∏ Í≤ÉÎ∂ÄÌÑ∞
        
        return hot_topics, cold_topics
    
    def calculate_ticker_sentiment_ranking(self, days: int = 7, top_count: int = 10,
                                         bottom_count: int = 10, min_mentions: int = 2) -> Tuple[List[Dict], List[Dict]]:
        """Ìã∞Ïª§Î≥Ñ Í∞êÏÑ± Îû≠ÌÇπÏùÑ Í≥ÑÏÇ∞Ìï©ÎãàÎã§."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # PostgreSQL JSONB ÏßëÍ≥Ñ ÏøºÎ¶¨
        query = text("""
            WITH ticker_stats AS (
                SELECT 
                    jsonb_array_elements(ticker_sentiment)->>'ticker' as ticker,
                    AVG((jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float) as avg_sentiment,
                    COUNT(*) as mention_count,
                    AVG((jsonb_array_elements(ticker_sentiment)->>'relevance_score')::float) as avg_relevance
                FROM market_news_sentiment 
                WHERE time_published >= :cutoff_date
                AND ticker_sentiment IS NOT NULL
                GROUP BY jsonb_array_elements(ticker_sentiment)->>'ticker'
                HAVING COUNT(*) >= :min_mentions
            )
            SELECT ticker, avg_sentiment, mention_count, avg_relevance
            FROM ticker_stats
            ORDER BY avg_sentiment DESC
        """)
        
        result = self.db.execute(query, {
            "cutoff_date": cutoff_date,
            "min_mentions": min_mentions
        }).fetchall()
        
        # Í≤∞Í≥º Ï≤òÎ¶¨
        all_tickers = []
        for row in result:
            ticker, avg_sentiment, mention_count, avg_relevance = row
            
            # Í∞êÏÑ± ÎùºÎ≤® Í≤∞Ï†ï
            sentiment_label, sentiment_emoji = self._get_sentiment_label_and_emoji(avg_sentiment)
            
            # Í¥ÄÎ†® Ï£ºÏ†ú Ï°∞Ìöå
            related_topics = self._get_topics_by_ticker(ticker, days)
            
            ticker_data = {
                "ticker": ticker,
                "avg_sentiment_score": float(avg_sentiment),
                "sentiment_label": sentiment_label,
                "sentiment_emoji": sentiment_emoji,
                "mention_count": mention_count,
                "avg_relevance_score": float(avg_relevance),
                "related_topics": related_topics[:3]  # ÏÉÅÏúÑ 3Í∞úÎßå
            }
            all_tickers.append(ticker_data)
        
        # Hot & Cold Î∂ÑÎ¶¨
        hot_tickers = all_tickers[:top_count]
        cold_tickers = all_tickers[-bottom_count:] if len(all_tickers) > bottom_count else []
        cold_tickers.reverse()  # Í∞ÄÏû• Î∂ÄÏ†ïÏ†ÅÏù∏ Í≤ÉÎ∂ÄÌÑ∞
        
        return hot_tickers, cold_tickers
    
    def calculate_topic_sentiment_summary(self, topic: str, days: int = 7) -> Dict[str, Any]:
        """ÌäπÏ†ï Ï£ºÏ†úÏùò Í∞êÏÑ± ÏöîÏïΩÏùÑ Í≥ÑÏÇ∞Ìï©ÎãàÎã§."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            SELECT 
                AVG(overall_sentiment_score) as avg_sentiment,
                COUNT(*) as total_news,
                COUNT(CASE WHEN overall_sentiment_score > 0.1 THEN 1 END) as bullish_count,
                COUNT(CASE WHEN overall_sentiment_score < -0.1 THEN 1 END) as bearish_count,
                COUNT(CASE WHEN overall_sentiment_score BETWEEN -0.1 AND 0.1 THEN 1 END) as neutral_count
            FROM market_news_sentiment 
            WHERE topics @> :topic_filter
            AND time_published >= :cutoff_date
            AND overall_sentiment_score IS NOT NULL
        """)
        
        topic_filter = json.dumps([{"topic": topic}])
        result = self.db.execute(query, {
            "topic_filter": topic_filter,
            "cutoff_date": cutoff_date
        }).fetchone()
        
        if not result or result[0] is None:
            return {
                "avg_sentiment_score": 0.0,
                "sentiment_label": "Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå",
                "sentiment_emoji": "‚ùì",
                "total_news": 0,
                "sentiment_distribution": {"bullish": 0, "bearish": 0, "neutral": 0}
            }
        
        avg_sentiment, total_news, bullish_count, bearish_count, neutral_count = result
        sentiment_label, sentiment_emoji = self._get_sentiment_label_and_emoji(avg_sentiment)
        
        return {
            "avg_sentiment_score": float(avg_sentiment),
            "sentiment_label": sentiment_label,
            "sentiment_emoji": sentiment_emoji,
            "total_news": total_news,
            "sentiment_distribution": {
                "bullish": bullish_count,
                "bearish": bearish_count,
                "neutral": neutral_count
            }
        }
    
    def calculate_ticker_sentiment_summary(self, ticker: str, days: int = 7) -> Dict[str, Any]:
        """ÌäπÏ†ï Ìã∞Ïª§Ïùò Í∞êÏÑ± ÏöîÏïΩÏùÑ Í≥ÑÏÇ∞Ìï©ÎãàÎã§."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            SELECT 
                AVG((jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float) as avg_sentiment,
                COUNT(*) as mention_count,
                AVG((jsonb_array_elements(ticker_sentiment)->>'relevance_score')::float) as avg_relevance
            FROM market_news_sentiment 
            WHERE ticker_sentiment @> :ticker_filter
            AND time_published >= :cutoff_date
        """)
        
        ticker_filter = json.dumps([{"ticker": ticker}])
        result = self.db.execute(query, {
            "ticker_filter": ticker_filter,
            "cutoff_date": cutoff_date
        }).fetchone()
        
        if not result or result[0] is None:
            return {
                "avg_sentiment_score": 0.0,
                "sentiment_label": "Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå",
                "sentiment_emoji": "‚ùì",
                "mention_count": 0,
                "avg_relevance_score": 0.0
            }
        
        avg_sentiment, mention_count, avg_relevance = result
        sentiment_label, sentiment_emoji = self._get_sentiment_label_and_emoji(avg_sentiment)
        
        return {
            "avg_sentiment_score": float(avg_sentiment),
            "sentiment_label": sentiment_label,
            "sentiment_emoji": sentiment_emoji,
            "mention_count": mention_count,
            "avg_relevance_score": float(avg_relevance)
        }
    
    # =========================================================================
    # ÌÅ¨Î°úÏä§ Î∂ÑÏÑù Î©îÏÑúÎìú
    # =========================================================================
    
    def get_tickers_by_topic(self, topic: str, days: int = 7, limit: int = 10) -> List[Dict]:
        """ÌäπÏ†ï Ï£ºÏ†úÏôÄ Í¥ÄÎ†®Îêú Ìã∞Ïª§Îì§ÏùÑ Ï°∞ÌöåÌï©ÎãàÎã§."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            WITH topic_tickers AS (
                SELECT 
                    jsonb_array_elements(ticker_sentiment)->>'ticker' as ticker,
                    AVG((jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float) as avg_sentiment,
                    COUNT(*) as mention_count
                FROM market_news_sentiment 
                WHERE topics @> :topic_filter
                AND time_published >= :cutoff_date
                AND ticker_sentiment IS NOT NULL
                GROUP BY jsonb_array_elements(ticker_sentiment)->>'ticker'
            )
            SELECT ticker, avg_sentiment, mention_count
            FROM topic_tickers
            ORDER BY mention_count DESC, avg_sentiment DESC
            LIMIT :limit
        """)
        
        topic_filter = json.dumps([{"topic": topic}])
        result = self.db.execute(query, {
            "topic_filter": topic_filter,
            "cutoff_date": cutoff_date,
            "limit": limit
        }).fetchall()
        
        return [
            {
                "ticker": row[0],
                "avg_sentiment_score": float(row[1]),
                "mention_count": row[2],
                "sentiment_label": self._get_sentiment_label_and_emoji(row[1])[0]
            }
            for row in result
        ]
    
    def get_topics_by_ticker(self, ticker: str, days: int = 7, limit: int = 10) -> List[Dict]:
        """ÌäπÏ†ï Ìã∞Ïª§ÏôÄ Í¥ÄÎ†®Îêú Ï£ºÏ†úÎì§ÏùÑ Ï°∞ÌöåÌï©ÎãàÎã§."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            WITH ticker_topics AS (
                SELECT 
                    jsonb_array_elements(topics)->>'topic' as topic,
                    AVG((jsonb_array_elements(topics)->>'relevance_score')::float) as avg_relevance,
                    COUNT(*) as mention_count
                FROM market_news_sentiment 
                WHERE ticker_sentiment @> :ticker_filter
                AND time_published >= :cutoff_date
                AND topics IS NOT NULL
                GROUP BY jsonb_array_elements(topics)->>'topic'
            )
            SELECT topic, avg_relevance, mention_count
            FROM ticker_topics
            ORDER BY avg_relevance DESC, mention_count DESC
            LIMIT :limit
        """)
        
        ticker_filter = json.dumps([{"ticker": ticker}])
        result = self.db.execute(query, {
            "ticker_filter": ticker_filter,
            "cutoff_date": cutoff_date,
            "limit": limit
        }).fetchall()
        
        return [
            {
                "topic": row[0],
                "avg_relevance_score": float(row[1]),
                "mention_count": row[2]
            }
            for row in result
        ]
    
    # =========================================================================
    # ÎÇ¥Î∂Ä Ïú†Ìã∏Î¶¨Ìã∞ Î©îÏÑúÎìú
    # =========================================================================
    
    def _get_sentiment_label_and_emoji(self, score: Optional[float]) -> Tuple[str, str]:
        """Í∞êÏÑ± Ï†êÏàòÎ•º ÎùºÎ≤®Í≥º Ïù¥Î™®ÏßÄÎ°ú Î≥ÄÌôòÌï©ÎãàÎã§."""
        if score is None:
            return "Ïïå Ïàò ÏóÜÏùå", "‚ùì"
        
        score = float(score)
        if score >= 0.3:
            return "Îß§Ïö∞Í∏çÏ†ïÏ†Å", "üöÄ"
        elif score >= 0.1:
            return "Í∏çÏ†ïÏ†Å", "üìà"
        elif score >= -0.1:
            return "Ï§ëÎ¶ΩÏ†Å", "‚û°Ô∏è"
        elif score >= -0.3:
            return "Î∂ÄÏ†ïÏ†Å", "üìâ"
        else:
            return "Îß§Ïö∞Î∂ÄÏ†ïÏ†Å", "üîª"
    
    def _get_tickers_by_topic(self, topic: str, days: int = 7) -> List[str]:
        """ÌäπÏ†ï Ï£ºÏ†úÏùò Í¥ÄÎ†® Ìã∞Ïª§ Î™©Î°ùÏùÑ Ï°∞ÌöåÌï©ÎãàÎã§."""
        tickers_data = self.get_tickers_by_topic(topic, days, 10)
        return [item["ticker"] for item in tickers_data]
    
    def _get_topics_by_ticker(self, ticker: str, days: int = 7) -> List[str]:
        """ÌäπÏ†ï Ìã∞Ïª§Ïùò Í¥ÄÎ†® Ï£ºÏ†ú Î™©Î°ùÏùÑ Ï°∞ÌöåÌï©ÎãàÎã§."""
        topics_data = self.get_topics_by_ticker(ticker, days, 10)
        return [item["topic"] for item in topics_data]
    
    # =========================================================================
    # Í∞êÏ†ï Ï†êÏàò Ï∂îÏù¥ Î©îÏÑúÎìú (ÌîÑÎ°†Ìä∏ÏóîÎìú Ï∞®Ìä∏Ïö©)
    # =========================================================================
    
    def get_sentiment_trends(self, interval: str = "daily", days: int = 7, 
                           tickers: Optional[List[str]] = None, 
                           topics: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        ÏãúÍ∞ÑÎåÄÎ≥Ñ Í∞êÏ†ï Ï†êÏàò Ï∂îÏù¥Î•º Í≥ÑÏÇ∞Ìï©ÎãàÎã§.
        
        Args:
            interval: 'hourly' ÎòêÎäî 'daily'
            days: Î∂ÑÏÑù Í∏∞Í∞Ñ
            tickers: ÌäπÏ†ï Ìã∞Ïª§Îì§Ïùò Ï∂îÏù¥ (ÏÑ†ÌÉùÏÇ¨Ìï≠)
            topics: ÌäπÏ†ï Ï£ºÏ†úÎì§Ïùò Ï∂îÏù¥ (ÏÑ†ÌÉùÏÇ¨Ìï≠)
            
        Returns:
            Dict: Ï†ÑÏ≤¥/Ìã∞Ïª§Î≥Ñ/Ï£ºÏ†úÎ≥Ñ Í∞êÏ†ï Ï†êÏàò Ï∂îÏù¥
        """
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # ÏãúÍ∞Ñ Í∞ÑÍ≤© ÏÑ§Ï†ï
        if interval == "hourly":
            date_trunc = "hour"
            interval_text = "ÏãúÍ∞ÑÎ≥Ñ"
        else:
            date_trunc = "day"
            interval_text = "ÏùºÎ≥Ñ"
        
        # Ï†ÑÏ≤¥ Í∞êÏ†ï Ï†êÏàò Ï∂îÏù¥
        overall_trend = self._calculate_overall_sentiment_trend(cutoff_date, date_trunc)
        
        # Ìã∞Ïª§Î≥Ñ Ï∂îÏù¥ (ÏöîÏ≤≠Îêú Í≤ΩÏö∞)
        ticker_trends = []
        if tickers:
            for ticker in tickers:
                trend_data = self._calculate_ticker_sentiment_trend(ticker, cutoff_date, date_trunc)
                if trend_data:
                    ticker_trends.append({
                        "ticker": ticker,
                        "trend_data": trend_data
                    })
        
        # Ï£ºÏ†úÎ≥Ñ Ï∂îÏù¥ (ÏöîÏ≤≠Îêú Í≤ΩÏö∞)
        topic_trends = []
        if topics:
            for topic in topics:
                trend_data = self._calculate_topic_sentiment_trend(topic, cutoff_date, date_trunc)
                if trend_data:
                    topic_trends.append({
                        "topic": topic,
                        "trend_data": trend_data
                    })
        
        return {
            "period": f"ÏµúÍ∑º {days}Ïùº",
            "interval": interval_text,
            "overall_trend": overall_trend,
            "ticker_trends": ticker_trends,
            "topic_trends": topic_trends
        }
    
    def _calculate_overall_sentiment_trend(self, cutoff_date: datetime, date_trunc: str) -> List[Dict]:
        """Ï†ÑÏ≤¥ Í∞êÏ†ï Ï†êÏàò Ï∂îÏù¥Î•º Í≥ÑÏÇ∞Ìï©ÎãàÎã§."""
        query = text(f"""
            SELECT 
                DATE_TRUNC('{date_trunc}', time_published) as time_period,
                AVG(overall_sentiment_score) as avg_sentiment,
                COUNT(*) as news_count,
                COUNT(CASE WHEN overall_sentiment_score > 0.1 THEN 1 END) as bullish_count,
                COUNT(CASE WHEN overall_sentiment_score < -0.1 THEN 1 END) as bearish_count,
                COUNT(CASE WHEN overall_sentiment_score BETWEEN -0.1 AND 0.1 THEN 1 END) as neutral_count
            FROM market_news_sentiment 
            WHERE time_published >= :cutoff_date
            AND overall_sentiment_score IS NOT NULL
            GROUP BY DATE_TRUNC('{date_trunc}', time_published)
            ORDER BY time_period
        """)
        
        result = self.db.execute(query, {"cutoff_date": cutoff_date}).fetchall()
        
        return [
            {
                "timestamp": row[0],
                "avg_sentiment_score": float(row[1]) if row[1] else 0.0,
                "news_count": row[2],
                "bullish_count": row[3],
                "bearish_count": row[4],
                "neutral_count": row[5]
            }
            for row in result
        ]
    
    def _calculate_ticker_sentiment_trend(self, ticker: str, cutoff_date: datetime, date_trunc: str) -> List[Dict]:
        """ÌäπÏ†ï Ìã∞Ïª§Ïùò Í∞êÏ†ï Ï†êÏàò Ï∂îÏù¥Î•º Í≥ÑÏÇ∞Ìï©ÎãàÎã§."""
        query = text(f"""
            SELECT 
                DATE_TRUNC('{date_trunc}', time_published) as time_period,
                AVG((jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float) as avg_sentiment,
                COUNT(*) as news_count,
                COUNT(CASE WHEN (jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float > 0.1 THEN 1 END) as bullish_count,
                COUNT(CASE WHEN (jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float < -0.1 THEN 1 END) as bearish_count,
                COUNT(CASE WHEN (jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float BETWEEN -0.1 AND 0.1 THEN 1 END) as neutral_count
            FROM market_news_sentiment 
            WHERE ticker_sentiment @> :ticker_filter
            AND time_published >= :cutoff_date
            GROUP BY DATE_TRUNC('{date_trunc}', time_published)
            ORDER BY time_period
        """)
        
        ticker_filter = json.dumps([{"ticker": ticker}])
        result = self.db.execute(query, {
            "ticker_filter": ticker_filter,
            "cutoff_date": cutoff_date
        }).fetchall()
        
        return [
            {
                "timestamp": row[0],
                "avg_sentiment_score": float(row[1]) if row[1] else 0.0,
                "news_count": row[2],
                "bullish_count": row[3],
                "bearish_count": row[4],
                "neutral_count": row[5]
            }
            for row in result
        ]
    
    def _calculate_topic_sentiment_trend(self, topic: str, cutoff_date: datetime, date_trunc: str) -> List[Dict]:
        """ÌäπÏ†ï Ï£ºÏ†úÏùò Í∞êÏ†ï Ï†êÏàò Ï∂îÏù¥Î•º Í≥ÑÏÇ∞Ìï©ÎãàÎã§."""
        query = text(f"""
            SELECT 
                DATE_TRUNC('{date_trunc}', time_published) as time_period,
                AVG(overall_sentiment_score) as avg_sentiment,
                COUNT(*) as news_count,
                COUNT(CASE WHEN overall_sentiment_score > 0.1 THEN 1 END) as bullish_count,
                COUNT(CASE WHEN overall_sentiment_score < -0.1 THEN 1 END) as bearish_count,
                COUNT(CASE WHEN overall_sentiment_score BETWEEN -0.1 AND 0.1 THEN 1 END) as neutral_count
            FROM market_news_sentiment 
            WHERE topics @> :topic_filter
            AND time_published >= :cutoff_date
            AND overall_sentiment_score IS NOT NULL
            GROUP BY DATE_TRUNC('{date_trunc}', time_published)
            ORDER BY time_period
        """)
        
        topic_filter = json.dumps([{"topic": topic}])
        result = self.db.execute(query, {
            "topic_filter": topic_filter,
            "cutoff_date": cutoff_date
        }).fetchall()
        
        return [
            {
                "timestamp": row[0],
                "avg_sentiment_score": float(row[1]) if row[1] else 0.0,
                "news_count": row[2],
                "bullish_count": row[3],
                "bearish_count": row[4],
                "neutral_count": row[5]
            }
            for row in result
        ]