from sqlalchemy.orm import Session
from sqlalchemy import func, and_, desc, asc, text
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime, timedelta
import json

from app.models.market_news_sentiment_model import MarketNewsSentiment

class MarketNewsSentimentService:
    """
    ì‹œì¥ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. JSONB ë°ì´í„° íŒŒì‹± (ticker_sentiment, topics)
    2. ê°ì„± ì ìˆ˜ ê¸°ë°˜ ë¶„ì„ ë° ë­í‚¹
    3. ì£¼ì œë³„/í‹°ì»¤ë³„ í•„í„°ë§
    4. í¬ë¡œìŠ¤ ë¶„ì„ (ì£¼ì œâ†”í‹°ì»¤ ê´€ê³„)
    """
    
    def __init__(self, db: Session):
        self.db = db
    
    # =========================================================================
    # JSONB ë°ì´í„° íŒŒì‹± ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ
    # =========================================================================
    
    def parse_ticker_sentiment(self, ticker_sentiment_json: Any) -> List[Dict]:
        """
        ticker_sentiment JSONB ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            ticker_sentiment_json: JSONB ë°ì´í„° (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)
            
        Returns:
            List[Dict]: íŒŒì‹±ëœ í‹°ì»¤ ê°ì„± ë°ì´í„°
        """
        if not ticker_sentiment_json:
            return []
            
        try:
            if isinstance(ticker_sentiment_json, str):
                data = json.loads(ticker_sentiment_json)
            else:
                data = ticker_sentiment_json
                
            result = []
            for item in data:
                result.append({
                    "ticker": item.get("ticker", ""),
                    "relevance_score": float(item.get("relevance_score", 0)),
                    "ticker_sentiment_label": item.get("ticker_sentiment_label", "Neutral"),
                    "ticker_sentiment_score": float(item.get("ticker_sentiment_score", 0))
                })
            return result
        except (json.JSONDecodeError, TypeError, KeyError):
            return []
    
    def parse_topics(self, topics_json: Any) -> List[Dict]:
        """
        topics JSONB ë°ì´í„°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        Args:
            topics_json: JSONB ë°ì´í„° (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)
            
        Returns:
            List[Dict]: íŒŒì‹±ëœ ì£¼ì œ ê´€ë ¨ë„ ë°ì´í„°
        """
        if not topics_json:
            return []
            
        try:
            if isinstance(topics_json, str):
                data = json.loads(topics_json)
            else:
                data = topics_json
                
            result = []
            for item in data:
                result.append({
                    "topic": item.get("topic", ""),
                    "relevance_score": float(item.get("relevance_score", 0))
                })
            return result
        except (json.JSONDecodeError, TypeError, KeyError):
            return []
    
    def enrich_news_with_jsonb_data(self, news_items: List[MarketNewsSentiment]) -> List[Dict]:
        """
        ë‰´ìŠ¤ ì•„ì´í…œì— JSONB ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ì¶”ê°€í•©ë‹ˆë‹¤.
        
        Args:
            news_items: ì›ë³¸ ë‰´ìŠ¤ ë°ì´í„°
            
        Returns:
            List[Dict]: JSONB ë°ì´í„°ê°€ íŒŒì‹±ëœ ë‰´ìŠ¤ ë°ì´í„°
        """
        enriched_news = []
        
        for news in news_items:
            news_dict = {
                "batch_id": news.batch_id,
                "url": news.url,
                "title": news.title,
                "time_published": news.time_published,
                "authors": news.authors,
                "summary": news.summary,
                "source": news.source,
                "overall_sentiment_score": float(news.overall_sentiment_score) if news.overall_sentiment_score else None,
                "overall_sentiment_label": news.overall_sentiment_label,
                "query_type": news.query_type,
                "query_params": news.query_params,
                "created_at": news.created_at,
                
                # ê°ì„± í•´ì„ ì¶”ê°€
                "sentiment_interpretation": news.sentiment_interpretation,
                "sentiment_emoji": news.sentiment_emoji,
                
                # JSONB ë°ì´í„° íŒŒì‹±
                "related_tickers": self.parse_ticker_sentiment(news.ticker_sentiment),
                "related_topics": self.parse_topics(news.topics)
            }
            enriched_news.append(news_dict)
            
        return enriched_news
    
    # =========================================================================
    # ê¸°ë³¸ ë‰´ìŠ¤ ì¡°íšŒ ë©”ì„œë“œ
    # =========================================================================
    
    def get_latest_batch_id(self) -> Optional[int]:
        """ìµœì‹  ë°°ì¹˜ IDë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        result = self.db.query(func.max(MarketNewsSentiment.batch_id)).scalar()
        return result if result else None
    
    def get_batch_info(self) -> Dict[str, Any]:
        """ë°°ì¹˜ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        latest_batch_id = self.get_latest_batch_id()
        
        # ì´ ë°°ì¹˜ ìˆ˜ ì¡°íšŒ
        total_batches = self.db.query(func.count(func.distinct(MarketNewsSentiment.batch_id))).scalar()
        
        # ìµœì‹  ë°°ì¹˜ì˜ ìˆ˜ì§‘ ë‚ ì§œ ì¡°íšŒ
        collection_date = "ì•Œ ìˆ˜ ì—†ìŒ"
        if latest_batch_id:
            latest_news = (self.db.query(MarketNewsSentiment)
                          .filter(MarketNewsSentiment.batch_id == latest_batch_id)
                          .first())
            if latest_news and latest_news.created_at:
                collection_date = latest_news.created_at.strftime("%Y-%m-%d")
        
        return {
            "latest_batch_id": latest_batch_id or 0,
            "collection_date": collection_date,
            "total_batches": total_batches or 0
        }
    
    def get_news_list(self, days: int = 7, limit: int = 20, offset: int = 0,
                     min_sentiment: Optional[float] = None, max_sentiment: Optional[float] = None,
                     sentiment_labels: Optional[List[str]] = None,
                     sort_by: str = "time_published", order: str = "desc") -> Tuple[List[Dict], int]:
        """
        ë‰´ìŠ¤ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            days: ìµœê·¼ Nì¼ ë°ì´í„°
            limit: ê²°ê³¼ ê°œìˆ˜ ì œí•œ
            offset: í˜ì´ì§• ì˜¤í”„ì…‹
            min_sentiment: ìµœì†Œ ê°ì„± ì ìˆ˜
            max_sentiment: ìµœëŒ€ ê°ì„± ì ìˆ˜
            sentiment_labels: ê°ì„± ë¼ë²¨ í•„í„°
            sort_by: ì •ë ¬ ê¸°ì¤€
            order: ì •ë ¬ ìˆœì„œ
            
        Returns:
            Tuple[news_list, total_count]: ë‰´ìŠ¤ ëª©ë¡ê³¼ ì´ ê°œìˆ˜
        """
        # ê¸°ë³¸ ì¿¼ë¦¬
        query = self.db.query(MarketNewsSentiment)
        
        # ë‚ ì§œ í•„í„°
        cutoff_date = datetime.now() - timedelta(days=days)
        query = query.filter(MarketNewsSentiment.time_published >= cutoff_date)
        
        # ê°ì„± ì ìˆ˜ í•„í„°
        if min_sentiment is not None:
            query = query.filter(MarketNewsSentiment.overall_sentiment_score >= min_sentiment)
        if max_sentiment is not None:
            query = query.filter(MarketNewsSentiment.overall_sentiment_score <= max_sentiment)
        
        # ê°ì„± ë¼ë²¨ í•„í„°
        if sentiment_labels:
            query = query.filter(MarketNewsSentiment.overall_sentiment_label.in_(sentiment_labels))
        
        # ì´ ê°œìˆ˜ ê³„ì‚°
        total_count = query.count()
        
        # ì •ë ¬
        if sort_by == "sentiment_score":
            sort_column = MarketNewsSentiment.overall_sentiment_score
        elif sort_by == "time_published":
            sort_column = MarketNewsSentiment.time_published
        else:
            sort_column = MarketNewsSentiment.time_published
        
        if order == "desc":
            query = query.order_by(desc(sort_column))
        else:
            query = query.order_by(asc(sort_column))
        
        # í˜ì´ì§•
        news_items = query.limit(limit).offset(offset).all()
        
        # JSONB ë°ì´í„° íŒŒì‹±í•˜ì—¬ ë°˜í™˜
        enriched_news = self.enrich_news_with_jsonb_data(news_items)
        
        return enriched_news, total_count
    
    def get_news_by_batch(self, batch_id: int, limit: int = 20, offset: int = 0) -> List[Dict]:
        """íŠ¹ì • ë°°ì¹˜ì˜ ë‰´ìŠ¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        news_items = (self.db.query(MarketNewsSentiment)
                     .filter(MarketNewsSentiment.batch_id == batch_id)
                     .order_by(desc(MarketNewsSentiment.time_published))
                     .limit(limit)
                     .offset(offset)
                     .all())
        
        return self.enrich_news_with_jsonb_data(news_items)
    
    # =========================================================================
    # Topic & Ticker ê´€ë ¨ ë©”ì„œë“œ
    # =========================================================================
    
    def get_all_topics(self) -> List[str]:
        """ëª¨ë“  ì£¼ì œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        # PostgreSQL JSONB ì¿¼ë¦¬ë¡œ ëª¨ë“  topic ì¶”ì¶œ
        query = text("""
            SELECT DISTINCT jsonb_array_elements(topics)->>'topic' as topic
            FROM market_news_sentiment 
            WHERE topics IS NOT NULL
            ORDER BY topic
        """)
        
        result = self.db.execute(query).fetchall()
        return [row[0] for row in result if row[0]]
    
    def get_all_tickers(self) -> List[str]:
        """ëª¨ë“  í‹°ì»¤ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        # PostgreSQL JSONB ì¿¼ë¦¬ë¡œ ëª¨ë“  ticker ì¶”ì¶œ
        query = text("""
            SELECT DISTINCT jsonb_array_elements(ticker_sentiment)->>'ticker' as ticker
            FROM market_news_sentiment 
            WHERE ticker_sentiment IS NOT NULL
            ORDER BY ticker
        """)
        
        result = self.db.execute(query).fetchall()
        return [row[0] for row in result if row[0]]
    
    def get_news_by_topic(self, topic: str, days: int = 7, limit: int = 20, offset: int = 0) -> Tuple[List[Dict], Dict]:
        """íŠ¹ì • ì£¼ì œì˜ ë‰´ìŠ¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        # PostgreSQL JSONB ì—°ì‚°ì ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì£¼ì œ í•„í„°ë§
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            SELECT * FROM market_news_sentiment 
            WHERE topics @> :topic_filter
            AND time_published >= :cutoff_date
            ORDER BY time_published DESC
            LIMIT :limit OFFSET :offset
        """)
        
        topic_filter = json.dumps([{"topic": topic}])
        result = self.db.execute(query, {
            "topic_filter": topic_filter,
            "cutoff_date": cutoff_date,
            "limit": limit,
            "offset": offset
        }).fetchall()
        
        # ê²°ê³¼ë¥¼ MarketNewsSentiment ê°ì²´ë¡œ ë³€í™˜
        news_items = []
        for row in result:
            news_item = MarketNewsSentiment()
            for i, column in enumerate(MarketNewsSentiment.__table__.columns):
                setattr(news_item, column.name, row[i])
            news_items.append(news_item)
        
        enriched_news = self.enrich_news_with_jsonb_data(news_items)
        
        # ì£¼ì œë³„ ê°ì„± ìš”ì•½ ê³„ì‚°
        topic_summary = self.calculate_topic_sentiment_summary(topic, days)
        
        return enriched_news, topic_summary
    
    def get_news_by_ticker(self, ticker: str, days: int = 7, limit: int = 20, offset: int = 0) -> Tuple[List[Dict], Dict]:
        """íŠ¹ì • í‹°ì»¤ì˜ ë‰´ìŠ¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            SELECT * FROM market_news_sentiment 
            WHERE ticker_sentiment @> :ticker_filter
            AND time_published >= :cutoff_date
            ORDER BY time_published DESC
            LIMIT :limit OFFSET :offset
        """)
        
        ticker_filter = json.dumps([{"ticker": ticker}])
        result = self.db.execute(query, {
            "ticker_filter": ticker_filter,
            "cutoff_date": cutoff_date,
            "limit": limit,
            "offset": offset
        }).fetchall()
        
        # ê²°ê³¼ë¥¼ MarketNewsSentiment ê°ì²´ë¡œ ë³€í™˜
        news_items = []
        for row in result:
            news_item = MarketNewsSentiment()
            for i, column in enumerate(MarketNewsSentiment.__table__.columns):
                setattr(news_item, column.name, row[i])
            news_items.append(news_item)
        
        enriched_news = self.enrich_news_with_jsonb_data(news_items)
        
        # í‹°ì»¤ë³„ ê°ì„± ìš”ì•½ ê³„ì‚°
        ticker_summary = self.calculate_ticker_sentiment_summary(ticker, days)
        
        return enriched_news, ticker_summary
    
    # =========================================================================
    # ê°ì„± ë¶„ì„ ë° ë­í‚¹ ë©”ì„œë“œ
    # =========================================================================
    
    def get_sentiment_filtered_news(self, sentiment_type: str, days: int = 7, 
                                   limit: int = 20, offset: int = 0) -> List[Dict]:
        """ê°ì„±ë³„ë¡œ í•„í„°ë§ëœ ë‰´ìŠ¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = self.db.query(MarketNewsSentiment).filter(
            MarketNewsSentiment.time_published >= cutoff_date
        )
        
        # ê°ì„± íƒ€ì…ë³„ í•„í„°ë§
        if sentiment_type == "bullish":
            query = query.filter(MarketNewsSentiment.overall_sentiment_score > 0.1)
        elif sentiment_type == "bearish":
            query = query.filter(MarketNewsSentiment.overall_sentiment_score < -0.1)
        elif sentiment_type == "neutral":
            query = query.filter(
                and_(
                    MarketNewsSentiment.overall_sentiment_score >= -0.1,
                    MarketNewsSentiment.overall_sentiment_score <= 0.1
                )
            )
        
        news_items = (query.order_by(desc(MarketNewsSentiment.time_published))
                     .limit(limit)
                     .offset(offset)
                     .all())
        
        return self.enrich_news_with_jsonb_data(news_items)
    
    def calculate_topic_sentiment_ranking(self, days: int = 7, top_count: int = 10,
                                        bottom_count: int = 10, min_mentions: int = 2) -> Tuple[List[Dict], List[Dict]]:
        """ì£¼ì œë³„ ê°ì„± ë­í‚¹ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # PostgreSQL JSONB ì§‘ê³„ ì¿¼ë¦¬
        query = text("""
            WITH topic_stats AS (
                SELECT 
                    jsonb_array_elements(topics)->>'topic' as topic,
                    AVG(overall_sentiment_score) as avg_sentiment,
                    COUNT(*) as news_count,
                    AVG((jsonb_array_elements(topics)->>'relevance_score')::float) as avg_relevance
                FROM market_news_sentiment 
                WHERE time_published >= :cutoff_date
                AND topics IS NOT NULL
                AND overall_sentiment_score IS NOT NULL
                GROUP BY jsonb_array_elements(topics)->>'topic'
                HAVING COUNT(*) >= :min_mentions
            )
            SELECT topic, avg_sentiment, news_count, avg_relevance
            FROM topic_stats
            ORDER BY avg_sentiment DESC
        """)
        
        result = self.db.execute(query, {
            "cutoff_date": cutoff_date,
            "min_mentions": min_mentions
        }).fetchall()
        
        # ê²°ê³¼ ì²˜ë¦¬
        all_topics = []
        for row in result:
            topic, avg_sentiment, news_count, avg_relevance = row
            
            # ê°ì„± ë¼ë²¨ ê²°ì •
            sentiment_label, sentiment_emoji = self._get_sentiment_label_and_emoji(avg_sentiment)
            
            # ê´€ë ¨ í‹°ì»¤ ì¡°íšŒ
            related_tickers = self._get_tickers_by_topic(topic, days)
            
            topic_data = {
                "topic": topic,
                "avg_sentiment_score": float(avg_sentiment),
                "news_count": news_count,
                "sentiment_label": sentiment_label,
                "sentiment_emoji": sentiment_emoji,
                "trend": "ìƒìŠ¹" if avg_sentiment > 0.05 else "í•˜ë½" if avg_sentiment < -0.05 else "ì•ˆì •",
                "related_tickers": related_tickers[:5]  # ìƒìœ„ 5ê°œë§Œ
            }
            all_topics.append(topic_data)
        
        # Hot & Cold ë¶„ë¦¬
        hot_topics = all_topics[:top_count]
        cold_topics = all_topics[-bottom_count:] if len(all_topics) > bottom_count else []
        cold_topics.reverse()  # ê°€ì¥ ë¶€ì •ì ì¸ ê²ƒë¶€í„°
        
        return hot_topics, cold_topics
    
    def calculate_ticker_sentiment_ranking(self, days: int = 7, top_count: int = 10,
                                         bottom_count: int = 10, min_mentions: int = 2) -> Tuple[List[Dict], List[Dict]]:
        """í‹°ì»¤ë³„ ê°ì„± ë­í‚¹ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # PostgreSQL JSONB ì§‘ê³„ ì¿¼ë¦¬
        query = text("""
            WITH ticker_stats AS (
                SELECT 
                    jsonb_array_elements(ticker_sentiment)->>'ticker' as ticker,
                    AVG((jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float) as avg_sentiment,
                    COUNT(*) as mention_count,
                    AVG((jsonb_array_elements(ticker_sentiment)->>'relevance_score')::float) as avg_relevance
                FROM market_news_sentiment 
                WHERE time_published >= :cutoff_date
                AND ticker_sentiment IS NOT NULL
                GROUP BY jsonb_array_elements(ticker_sentiment)->>'ticker'
                HAVING COUNT(*) >= :min_mentions
            )
            SELECT ticker, avg_sentiment, mention_count, avg_relevance
            FROM ticker_stats
            ORDER BY avg_sentiment DESC
        """)
        
        result = self.db.execute(query, {
            "cutoff_date": cutoff_date,
            "min_mentions": min_mentions
        }).fetchall()
        
        # ê²°ê³¼ ì²˜ë¦¬
        all_tickers = []
        for row in result:
            ticker, avg_sentiment, mention_count, avg_relevance = row
            
            # ê°ì„± ë¼ë²¨ ê²°ì •
            sentiment_label, sentiment_emoji = self._get_sentiment_label_and_emoji(avg_sentiment)
            
            # ê´€ë ¨ ì£¼ì œ ì¡°íšŒ
            related_topics = self._get_topics_by_ticker(ticker, days)
            
            ticker_data = {
                "ticker": ticker,
                "avg_sentiment_score": float(avg_sentiment),
                "sentiment_label": sentiment_label,
                "sentiment_emoji": sentiment_emoji,
                "mention_count": mention_count,
                "avg_relevance_score": float(avg_relevance),
                "related_topics": related_topics[:3]  # ìƒìœ„ 3ê°œë§Œ
            }
            all_tickers.append(ticker_data)
        
        # Hot & Cold ë¶„ë¦¬
        hot_tickers = all_tickers[:top_count]
        cold_tickers = all_tickers[-bottom_count:] if len(all_tickers) > bottom_count else []
        cold_tickers.reverse()  # ê°€ì¥ ë¶€ì •ì ì¸ ê²ƒë¶€í„°
        
        return hot_tickers, cold_tickers
    
    def calculate_topic_sentiment_summary(self, topic: str, days: int = 7) -> Dict[str, Any]:
        """íŠ¹ì • ì£¼ì œì˜ ê°ì„± ìš”ì•½ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            SELECT 
                AVG(overall_sentiment_score) as avg_sentiment,
                COUNT(*) as total_news,
                COUNT(CASE WHEN overall_sentiment_score > 0.1 THEN 1 END) as bullish_count,
                COUNT(CASE WHEN overall_sentiment_score < -0.1 THEN 1 END) as bearish_count,
                COUNT(CASE WHEN overall_sentiment_score BETWEEN -0.1 AND 0.1 THEN 1 END) as neutral_count
            FROM market_news_sentiment 
            WHERE topics @> :topic_filter
            AND time_published >= :cutoff_date
            AND overall_sentiment_score IS NOT NULL
        """)
        
        topic_filter = json.dumps([{"topic": topic}])
        result = self.db.execute(query, {
            "topic_filter": topic_filter,
            "cutoff_date": cutoff_date
        }).fetchone()
        
        if not result or result[0] is None:
            return {
                "avg_sentiment_score": 0.0,
                "sentiment_label": "ë°ì´í„° ì—†ìŒ",
                "sentiment_emoji": "â“",
                "total_news": 0,
                "sentiment_distribution": {"bullish": 0, "bearish": 0, "neutral": 0}
            }
        
        avg_sentiment, total_news, bullish_count, bearish_count, neutral_count = result
        sentiment_label, sentiment_emoji = self._get_sentiment_label_and_emoji(avg_sentiment)
        
        return {
            "avg_sentiment_score": float(avg_sentiment),
            "sentiment_label": sentiment_label,
            "sentiment_emoji": sentiment_emoji,
            "total_news": total_news,
            "sentiment_distribution": {
                "bullish": bullish_count,
                "bearish": bearish_count,
                "neutral": neutral_count
            }
        }
    
    def calculate_ticker_sentiment_summary(self, ticker: str, days: int = 7) -> Dict[str, Any]:
        """íŠ¹ì • í‹°ì»¤ì˜ ê°ì„± ìš”ì•½ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            SELECT 
                AVG((jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float) as avg_sentiment,
                COUNT(*) as mention_count,
                AVG((jsonb_array_elements(ticker_sentiment)->>'relevance_score')::float) as avg_relevance
            FROM market_news_sentiment 
            WHERE ticker_sentiment @> :ticker_filter
            AND time_published >= :cutoff_date
        """)
        
        ticker_filter = json.dumps([{"ticker": ticker}])
        result = self.db.execute(query, {
            "ticker_filter": ticker_filter,
            "cutoff_date": cutoff_date
        }).fetchone()
        
        if not result or result[0] is None:
            return {
                "avg_sentiment_score": 0.0,
                "sentiment_label": "ë°ì´í„° ì—†ìŒ",
                "sentiment_emoji": "â“",
                "mention_count": 0,
                "avg_relevance_score": 0.0
            }
        
        avg_sentiment, mention_count, avg_relevance = result
        sentiment_label, sentiment_emoji = self._get_sentiment_label_and_emoji(avg_sentiment)
        
        return {
            "avg_sentiment_score": float(avg_sentiment),
            "sentiment_label": sentiment_label,
            "sentiment_emoji": sentiment_emoji,
            "mention_count": mention_count,
            "avg_relevance_score": float(avg_relevance)
        }
    
    # =========================================================================
    # í¬ë¡œìŠ¤ ë¶„ì„ ë©”ì„œë“œ
    # =========================================================================
    
    def get_tickers_by_topic(self, topic: str, days: int = 7, limit: int = 10) -> List[Dict]:
        """íŠ¹ì • ì£¼ì œì™€ ê´€ë ¨ëœ í‹°ì»¤ë“¤ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            WITH topic_tickers AS (
                SELECT 
                    jsonb_array_elements(ticker_sentiment)->>'ticker' as ticker,
                    AVG((jsonb_array_elements(ticker_sentiment)->>'ticker_sentiment_score')::float) as avg_sentiment,
                    COUNT(*) as mention_count
                FROM market_news_sentiment 
                WHERE topics @> :topic_filter
                AND time_published >= :cutoff_date
                AND ticker_sentiment IS NOT NULL
                GROUP BY jsonb_array_elements(ticker_sentiment)->>'ticker'
            )
            SELECT ticker, avg_sentiment, mention_count
            FROM topic_tickers
            ORDER BY mention_count DESC, avg_sentiment DESC
            LIMIT :limit
        """)
        
        topic_filter = json.dumps([{"topic": topic}])
        result = self.db.execute(query, {
            "topic_filter": topic_filter,
            "cutoff_date": cutoff_date,
            "limit": limit
        }).fetchall()
        
        return [
            {
                "ticker": row[0],
                "avg_sentiment_score": float(row[1]),
                "mention_count": row[2],
                "sentiment_label": self._get_sentiment_label_and_emoji(row[1])[0]
            }
            for row in result
        ]
    
    def get_topics_by_ticker(self, ticker: str, days: int = 7, limit: int = 10) -> List[Dict]:
        """íŠ¹ì • í‹°ì»¤ì™€ ê´€ë ¨ëœ ì£¼ì œë“¤ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        query = text("""
            WITH ticker_topics AS (
                SELECT 
                    jsonb_array_elements(topics)->>'topic' as topic,
                    AVG((jsonb_array_elements(topics)->>'relevance_score')::float) as avg_relevance,
                    COUNT(*) as mention_count
                FROM market_news_sentiment 
                WHERE ticker_sentiment @> :ticker_filter
                AND time_published >= :cutoff_date
                AND topics IS NOT NULL
                GROUP BY jsonb_array_elements(topics)->>'topic'
            )
            SELECT topic, avg_relevance, mention_count
            FROM ticker_topics
            ORDER BY avg_relevance DESC, mention_count DESC
            LIMIT :limit
        """)
        
        ticker_filter = json.dumps([{"ticker": ticker}])
        result = self.db.execute(query, {
            "ticker_filter": ticker_filter,
            "cutoff_date": cutoff_date,
            "limit": limit
        }).fetchall()
        
        return [
            {
                "topic": row[0],
                "avg_relevance_score": float(row[1]),
                "mention_count": row[2]
            }
            for row in result
        ]
    
    # =========================================================================
    # ë‚´ë¶€ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ
    # =========================================================================
    
    def _get_sentiment_label_and_emoji(self, score: Optional[float]) -> Tuple[str, str]:
        """ê°ì„± ì ìˆ˜ë¥¼ ë¼ë²¨ê³¼ ì´ëª¨ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if score is None:
            return "ì•Œ ìˆ˜ ì—†ìŒ", "â“"
        
        score = float(score)
        if score >= 0.3:
            return "ë§¤ìš°ê¸ì •ì ", "ğŸš€"
        elif score >= 0.1:
            return "ê¸ì •ì ", "ğŸ“ˆ"
        elif score >= -0.1:
            return "ì¤‘ë¦½ì ", "â¡ï¸"
        elif score >= -0.3:
            return "ë¶€ì •ì ", "ğŸ“‰"
        else:
            return "ë§¤ìš°ë¶€ì •ì ", "ğŸ”»"
    
    def _get_tickers_by_topic(self, topic: str, days: int = 7) -> List[str]:
        """íŠ¹ì • ì£¼ì œì˜ ê´€ë ¨ í‹°ì»¤ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        tickers_data = self.get_tickers_by_topic(topic, days, 10)
        return [item["ticker"] for item in tickers_data]
    
    def _get_topics_by_ticker(self, ticker: str, days: int = 7) -> List[str]:
        """íŠ¹ì • í‹°ì»¤ì˜ ê´€ë ¨ ì£¼ì œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        topics_data = self.get_topics_by_ticker(ticker, days, 10)
        return [item["topic"] for item in topics_data]