from datetime import datetime, timedelta
import os
import requests
from decimal import Decimal

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.models import Variable

# SQL íŒŒì¼ ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "..", "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_federal_funds_rate.sql"), encoding="utf-8") as f:
    UPSERT_SQL = f.read()

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}



def fetch_federal_funds_rate(**context):
    """ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ ë°ì´í„° ìˆ˜ì§‘"""
    api_key = Variable.get('ALPHA_VANTAGE_API_KEY')
    url = 'https://www.alphavantage.co/query'
    
    params = {
        'function': 'FEDERAL_FUNDS_RATE',
        'interval': 'monthly',
        'datatype': 'json',
        'apikey': api_key
    }
    
    try:
        print("ğŸ›ï¸ ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        response = requests.get(url, params=params, timeout=60)
        response.raise_for_status()
        
        data = response.json()
        
        # API ì˜¤ë¥˜ í™•ì¸
        if 'Error Message' in data:
            raise ValueError(f"API ì˜¤ë¥˜: {data['Error Message']}")
            
        if 'Note' in data:
            raise ValueError(f"API ì œí•œ: {data['Note']}")
            
        if 'Information' in data:
            raise ValueError(f"API ì •ë³´: {data['Information']}")
        
        # ì‘ë‹µ êµ¬ì¡° í™•ì¸
        if 'data' not in data:
            raise ValueError(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ì‘ë‹µ êµ¬ì¡°: {list(data.keys())}")
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = {
            'name': data.get('name', 'Effective Federal Funds Rate'),
            'interval': data.get('interval', 'monthly'),
            'unit': data.get('unit', 'percent')
        }
        
        # ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
        time_series = data.get('data', [])
        
        if not time_series:
            raise ValueError("ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ìµœê·¼ 24ê°œì›” ë°ì´í„°ë§Œ ìˆ˜ì§‘ (API ì œí•œ ê³ ë ¤)
        recent_data = time_series[:24] if len(time_series) > 24 else time_series
        
        print(f"âœ… ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(recent_data)}ê°œ ë ˆì½”ë“œ")
        print(f"ğŸ“Š ë©”íƒ€ë°ì´í„°: {metadata}")
        print(f"ğŸ“… ë°ì´í„° ë²”ìœ„: {recent_data[-1]['date']} ~ {recent_data[0]['date']}")
        
        # XComì— ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥
        context['ti'].xcom_push(key='federal_funds_data', value=recent_data)
        context['ti'].xcom_push(key='metadata', value=metadata)
        
        return len(recent_data)
        
    except Exception as e:
        print(f"âŒ ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        raise

def upsert_federal_funds_rate(**context):
    """ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ ë°ì´í„° ì €ì¥"""
    # XComì—ì„œ ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    data = context['ti'].xcom_pull(task_ids='fetch_federal_funds_rate', key='federal_funds_data')
    metadata = context['ti'].xcom_pull(task_ids='fetch_federal_funds_rate', key='metadata')
    
    if not data:
        raise ValueError("ì´ì „ íƒœìŠ¤í¬ì—ì„œ ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
    
    if not metadata:
        metadata = {
            'name': 'Effective Federal Funds Rate',
            'interval': 'monthly', 
            'unit': 'percent'
        }
    
    hook = PostgresHook(postgres_conn_id='postgres_default')
    success_count = 0
    error_count = 0
    
    print(f"ğŸš€ ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ ë°ì´í„° ì €ì¥ ì‹œì‘: {len(data)}ê°œ ë ˆì½”ë“œ")
    print(f"ğŸ“Š ë©”íƒ€ë°ì´í„°: {metadata}")
    
    for i, item in enumerate(data):
        try:
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            if not item.get('date') or not item.get('value'):
                print(f"âš ï¸ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {item}")
                error_count += 1
                continue
            
            # valueê°€ "." ë˜ëŠ” ë¹ˆ ê°’ì¸ ê²½ìš° ì²˜ë¦¬
            rate_value = item['value']
            if rate_value in ['.', '', 'null', None]:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ê°’: {item['date']} = {rate_value}")
                rate_value = None
            else:
                try:
                    rate_value = float(rate_value)
                except (ValueError, TypeError):
                    print(f"âš ï¸ ìˆ«ì ë³€í™˜ ì‹¤íŒ¨: {item['date']} = {rate_value}")
                    rate_value = None
            
            # ë°ì´í„° ë³€í™˜
            processed_item = {
                'date': item['date'],
                'rate': rate_value,
                'interval_type': metadata['interval'],
                'unit': metadata['unit'],
                'name': metadata['name']
            }
            
            # SQL ì‹¤í–‰
            hook.run(UPSERT_SQL, parameters=processed_item)
            success_count += 1
            
            # ì§„í–‰ë¥  í‘œì‹œ (10ê°œë§ˆë‹¤)
            if (i + 1) % 10 == 0:
                print(f"ğŸ“Š ì§„í–‰ë¥ : {i+1}/{len(data)}")
                
        except Exception as e:
            print(f"âŒ ë ˆì½”ë“œ ì €ì¥ ì‹¤íŒ¨: {item.get('date', 'Unknown')} - {str(e)}")
            error_count += 1
            continue
    
    # ìµœì¢… í†µê³„
    print(f"âœ… ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")
    
    # ì „ì²´ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
    result = hook.get_first("SELECT COUNT(*) FROM federal_funds_rate")
    total_records = result[0] if result else 0
    print(f"ğŸ“Š ì´ ë ˆì½”ë“œ ìˆ˜: {total_records}")
    
    # ìµœì‹  5ê°œ ë ˆì½”ë“œ í™•ì¸
    latest_records = hook.get_records(
        "SELECT date, rate FROM federal_funds_rate ORDER BY date DESC LIMIT 5"
    )
    print(f"ğŸ“… ìµœì‹  5ê°œ ë ˆì½”ë“œ:")
    for record in latest_records:
        print(f"   {record[0]}: {record[1]}%")
    
    return success_count

# DAG ì •ì˜
with DAG(
    dag_id='ingest_federal_funds_rate_to_db',
    default_args=default_args,
    schedule_interval='@monthly',  # ì›” 1íšŒ ì‹¤í–‰
    catchup=False,
    description='Alpha Vantage FEDERAL_FUNDS_RATE ë°ì´í„° ìˆ˜ì§‘',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['economic_indicators', 'alpha_vantage', 'federal_funds_rate', 'interest_rate'],
) as dag:
    
    # í…Œì´ë¸” ìƒì„±
    create_table = PostgresOperator(
        task_id='create_federal_funds_rate_table',
        postgres_conn_id='postgres_default',
        sql='create_federal_funds_rate.sql',
    )
    
    # ë°ì´í„° ìˆ˜ì§‘
    fetch_data = PythonOperator(
        task_id='fetch_federal_funds_rate',
        python_callable=fetch_federal_funds_rate,
    )
    
    # ë°ì´í„° ì €ì¥
    upsert_data = PythonOperator(
        task_id='upsert_federal_funds_rate',
        python_callable=upsert_federal_funds_rate,
    )
    
    # Task ì˜ì¡´ì„±
    create_table >> fetch_data >> upsert_data