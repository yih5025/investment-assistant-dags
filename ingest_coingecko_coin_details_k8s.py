from datetime import datetime, timedelta
import os
import requests
from decimal import Decimal
import json
import time

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.models import Variable

# í‘œì¤€ ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_coingecko_coin_details.sql"), encoding="utf-8") as f:
    UPSERT_SQL = f.read()

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

def get_target_coin_ids(**context):
    """
    ì²˜ë¦¬í•  ì½”ì¸ ID ëª©ë¡ ì¡°íšŒ (ìƒìœ„ 100ê°œ + ë¹—ì¸ ìƒì¥ ì½”ì¸)
    """
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    # ìƒìœ„ 100ê°œ ì½”ì¸ + ë¹—ì¸ ìƒì¥ ì½”ì¸ (ì¤‘ë³µ ì œê±°)
    query = """
    WITH target_coins AS (
        -- ìƒìœ„ 100ê°œ ì½”ì¸
        SELECT coingecko_id, symbol, name, market_cap_rank, 'top100' as source
        FROM coingecko_id_mapping 
        WHERE market_cap_rank <= 100
        
        UNION
        
        -- ë¹—ì¸ ìƒì¥ ì½”ì¸ (ì‹¬ë³¼ ë§¤ì¹­)
        SELECT DISTINCT 
            cg.coingecko_id, 
            cg.symbol, 
            cg.name, 
            cg.market_cap_rank,
            'bithumb' as source
        FROM coingecko_id_mapping cg
        INNER JOIN market_code_bithumb mb ON UPPER(cg.symbol) = UPPER(REPLACE(mb.market_code, 'KRW-', ''))
        WHERE cg.market_cap_rank <= 1000  -- ìƒìœ„ 1000ê°œ ë‚´ì—ì„œë§Œ
    )
    SELECT coingecko_id, symbol, name, market_cap_rank
    FROM target_coins
    ORDER BY market_cap_rank NULLS LAST, coingecko_id
    LIMIT 200;  -- ìµœëŒ€ 200ê°œ
    """
    
    results = hook.get_records(query)
    coin_list = [{'id': row[0], 'symbol': row[1], 'name': row[2], 'rank': row[3]} for row in results]
    
    print(f"ğŸ¯ ì²˜ë¦¬í•  ì½”ì¸ {len(coin_list)}ê°œ ì¡°íšŒ ì™„ë£Œ")
    
    # XComì— ì €ì¥
    context['ti'].xcom_push(key='coin_list', value=coin_list)
    return {'total_coins': len(coin_list)}

def fetch_coin_details_batch(**context):
    """
    ì½”ì¸ ìƒì„¸ ì •ë³´ ë°°ì¹˜ ìˆ˜ì§‘ (Rate Limit ê³ ë ¤)
    """
    # XComì—ì„œ ì½”ì¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    coin_list = context['ti'].xcom_pull(task_ids='get_target_coin_ids', key='coin_list')
    
    if not coin_list:
        raise ValueError("âŒ ì²˜ë¦¬í•  ì½”ì¸ ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤")
    
    API_BASE_URL = "https://api.coingecko.com/api/v3/coins"
    BATCH_SIZE = 10  # Rate Limit ê³ ë ¤
    
    # Airflow Variableì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    api_key = Variable.get("coingecko_api_key_1", default_var=None)
    
    # í—¤ë” ì„¤ì • (API í‚¤ í¬í•¨)
    headers = {
        'User-Agent': 'Investment-Assistant/1.0',
        'Accept': 'application/json'
    }
    
    if api_key:
        headers['x-cg-demo-api-key'] = api_key
        print(f"ğŸ”‘ API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤")
    else:
        print(f"âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Rate limitì´ ì ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    all_results = []
    
    # ë°°ì¹˜ë³„ ì²˜ë¦¬
    for i in range(0, len(coin_list), BATCH_SIZE):
        batch = coin_list[i:i + BATCH_SIZE]
        batch_num = (i // BATCH_SIZE) + 1
        
        print(f"ğŸ“¦ ë°°ì¹˜ {batch_num} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ ì½”ì¸)")
        
        for coin in batch:
            coin_id = coin['id']
            
            # ì¬ì‹œë„ ë¡œì§
            for attempt in range(3):
                try:
                    url = f"{API_BASE_URL}/{coin_id}"
                    params = {
                        'localization': 'false',
                        'tickers': 'false', 
                        'market_data': 'true',
                        'community_data': 'true',
                        'developer_data': 'true',
                        'sparkline': 'false'
                    }
                    
                    response = requests.get(
                        url,
                        params=params,
                        timeout=30,
                        headers=headers
                    )
                    
                    if response.status_code == 200:
                        coin_data = response.json()
                        all_results.append({
                            'coin_id': coin_id,
                            'status': 'success',
                            'data': coin_data
                        })
                        print(f"âœ… {coin_id} ìˆ˜ì§‘ ì„±ê³µ")
                        break
                        
                    elif response.status_code == 429:  # Rate limit
                        wait_time = 60 * (attempt + 1)
                        print(f"âš ï¸ Rate limit ë„ë‹¬. {wait_time}ì´ˆ ëŒ€ê¸°")
                        if attempt < 2:
                            time.sleep(wait_time)
                            continue
                            
                    elif response.status_code == 404:
                        all_results.append({
                            'coin_id': coin_id,
                            'status': 'not_found',
                            'error': f'Coin {coin_id} not found'
                        })
                        print(f"âš ï¸ {coin_id} ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
                        break
                        
                    else:
                        raise ValueError(f"API ì˜¤ë¥˜: {response.status_code}")
                        
                except requests.RequestException as e:
                    print(f"âŒ {coin_id} ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/3): {str(e)}")
                    if attempt < 2:
                        time.sleep(2)
                        continue
            else:
                # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
                all_results.append({
                    'coin_id': coin_id,
                    'status': 'failed',
                    'error': 'All retries failed'
                })
            
            # Rate Limit ë°©ì§€
            time.sleep(1)
        
        # ë°°ì¹˜ ê°„ ëŒ€ê¸°
        if i + BATCH_SIZE < len(coin_list):
            print(f"â³ ë°°ì¹˜ ê°„ ëŒ€ê¸° (30ì´ˆ)")
            time.sleep(30)
    
    # ê²°ê³¼ í†µê³„
    success_count = len([r for r in all_results if r['status'] == 'success'])
    failed_count = len([r for r in all_results if r['status'] in ['failed', 'not_found']])
    
    print(f"ğŸ“Š ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    
    # XComì— ì €ì¥
    context['ti'].xcom_push(key='batch_results', value=all_results)
    
    return {
        'total_processed': len(all_results),
        'success_count': success_count,
        'failed_count': failed_count
    }

def process_and_store_details(**context):
    """
    ìˆ˜ì§‘ëœ ì½”ì¸ ìƒì„¸ ë°ì´í„°ë¥¼ ê°€ê³µí•˜ì—¬ PostgreSQLì— ì €ì¥
    """
    # XComì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    batch_results = context['ti'].xcom_pull(task_ids='fetch_coin_details_batch', key='batch_results')
    
    if not batch_results:
        raise ValueError("âŒ ì´ì „ íƒœìŠ¤í¬ì—ì„œ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
    
    # DB ì—°ê²°
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    success_count = 0
    error_count = 0
    
    print(f"ğŸš€ {len(batch_results)}ê°œ ì½”ì¸ ë°ì´í„° ì €ì¥ ì‹œì‘")
    
    for result in batch_results:
        coin_id = result['coin_id']
        
        if result['status'] != 'success':
            error_count += 1
            continue
        
        try:
            coin_data = result['data']
            
            # ë³µì¡í•œ ì¤‘ì²© ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ë“¤
            def safe_get(data, *keys, default=None):
                """ì¤‘ì²© ë”•ì…”ë„ˆë¦¬ì—ì„œ ì•ˆì „í•˜ê²Œ ê°’ ì¶”ì¶œ"""
                current = data
                for key in keys:
                    if isinstance(current, dict) and key in current:
                        current = current[key]
                    else:
                        return default
                return current
            
            def parse_date(date_str):
                """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±"""
                if date_str:
                    try:
                        return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                    except:
                        return None
                return None
            
            def extract_urls(links_dict, key):
                """ë§í¬ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì²« ë²ˆì§¸ URL ì¶”ì¶œ"""
                urls = safe_get(links_dict, key, [])
                return urls[0] if urls and len(urls) > 0 else None
            
            # ë°ì´í„° ì¶”ì¶œ
            links = safe_get(coin_data, 'links', {})
            market_data = safe_get(coin_data, 'market_data', {})
            community_data = safe_get(coin_data, 'community_data', {})
            developer_data = safe_get(coin_data, 'developer_data', {})
            image = safe_get(coin_data, 'image', {})
            
            # íŒŒë¼ë¯¸í„° ì¤€ë¹„
            params = {
                'coingecko_id': coin_data.get('id'),
                'symbol': coin_data.get('symbol', '').upper(),
                'name': coin_data.get('name', '')[:200],
                'web_slug': coin_data.get('web_slug', '')[:200],
                
                # Tab 1 ë°ì´í„°
                'description_en': safe_get(coin_data, 'description', 'en', '')[:5000],  # TEXT ì œí•œ
                'genesis_date': parse_date(coin_data.get('genesis_date')),
                'country_origin': coin_data.get('country_origin', '')[:100],
                
                # Links
                'homepage_url': extract_urls(links, 'homepage'),
                'blockchain_site': extract_urls(links, 'blockchain_site'),
                'twitter_screen_name': links.get('twitter_screen_name', '')[:100],
                'facebook_username': links.get('facebook_username', '')[:100],
                'telegram_channel_identifier': links.get('telegram_channel_identifier', '')[:100],
                'subreddit_url': links.get('subreddit_url', '')[:500],
                'github_repos': json.dumps(links.get('repos_url', {})) if links.get('repos_url') else None,
                
                # Images
                'image_thumb': image.get('thumb', '')[:500],
                'image_small': image.get('small', '')[:500],
                'image_large': image.get('large', '')[:500],
                
                # Categories
                'categories': json.dumps(coin_data.get('categories', [])),
                
                # Market Data (Tab 3)
                'current_price_usd': Decimal(str(safe_get(market_data, 'current_price', 'usd', 0))),
                'current_price_krw': Decimal(str(safe_get(market_data, 'current_price', 'krw', 0))) if safe_get(market_data, 'current_price', 'krw') else None,
                'market_cap_usd': int(safe_get(market_data, 'market_cap', 'usd', 0)) if safe_get(market_data, 'market_cap', 'usd') else None,
                'market_cap_rank': market_data.get('market_cap_rank'),
                'total_volume_usd': int(safe_get(market_data, 'total_volume', 'usd', 0)) if safe_get(market_data, 'total_volume', 'usd') else None,
                
                # ATH/ATL
                'ath_usd': Decimal(str(safe_get(market_data, 'ath', 'usd', 0))) if safe_get(market_data, 'ath', 'usd') else None,
                'ath_change_percentage': Decimal(str(safe_get(market_data, 'ath_change_percentage', 'usd', 0))) if safe_get(market_data, 'ath_change_percentage', 'usd') else None,
                'ath_date': parse_date(safe_get(market_data, 'ath_date', 'usd')),
                'atl_usd': Decimal(str(safe_get(market_data, 'atl', 'usd', 0))) if safe_get(market_data, 'atl', 'usd') else None,
                'atl_change_percentage': Decimal(str(safe_get(market_data, 'atl_change_percentage', 'usd', 0))) if safe_get(market_data, 'atl_change_percentage', 'usd') else None,
                'atl_date': parse_date(safe_get(market_data, 'atl_date', 'usd')),
                
                # Supply Data
                'total_supply': Decimal(str(market_data.get('total_supply', 0))) if market_data.get('total_supply') else None,
                'circulating_supply': Decimal(str(market_data.get('circulating_supply', 0))) if market_data.get('circulating_supply') else None,
                'max_supply': Decimal(str(market_data.get('max_supply', 0))) if market_data.get('max_supply') else None,
                
                # Price Changes
                'price_change_24h_usd': Decimal(str(market_data.get('price_change_24h', 0))),
                'price_change_percentage_24h': Decimal(str(market_data.get('price_change_percentage_24h', 0))),
                'price_change_percentage_7d': Decimal(str(market_data.get('price_change_percentage_7d', 0))),
                'price_change_percentage_30d': Decimal(str(market_data.get('price_change_percentage_30d', 0))),
                
                # Community Data (Tab 2)
                'community_score': Decimal(str(coin_data.get('community_score', 0))) if coin_data.get('community_score') else None,
                'twitter_followers': community_data.get('twitter_followers'),
                'reddit_subscribers': community_data.get('reddit_subscribers'),
                'telegram_channel_user_count': community_data.get('telegram_channel_user_count'),
                
                # Developer Data (Tab 2)
                'developer_score': Decimal(str(coin_data.get('developer_score', 0))) if coin_data.get('developer_score') else None,
                'forks': developer_data.get('forks'),
                'stars': developer_data.get('stars'),
                'total_issues': developer_data.get('total_issues'),
                'closed_issues': developer_data.get('closed_issues'),
                'commit_count_4_weeks': developer_data.get('commit_count_4_weeks'),
                
                # Other Scores
                'public_interest_score': Decimal(str(coin_data.get('public_interest_score', 0))) if coin_data.get('public_interest_score') else None,
                'liquidity_score': Decimal(str(coin_data.get('liquidity_score', 0))) if coin_data.get('liquidity_score') else None,
                
                # Timestamps
                'coingecko_last_updated': parse_date(coin_data.get('last_updated'))
            }
            
            # SQL ì‹¤í–‰
            hook.run(UPSERT_SQL, parameters=params)
            success_count += 1
            
        except Exception as e:
            print(f"âŒ ì½”ì¸ {coin_id} ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            error_count += 1
            continue
    
    print(f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")
    
    return {
        'success_count': success_count,
        'error_count': error_count,
        'execution_time': context['execution_date'].isoformat()
    }

# DAG ì •ì˜
with DAG(
    dag_id='ingest_coingecko_coin_details_k8s',
    default_args=default_args,
    schedule_interval='@daily',  # ë§¤ì¼ ì‹¤í–‰
    catchup=False,
    description='CoinGecko ì½”ì¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['coingecko', 'crypto', 'details', 'daily'],
) as dag:
    
    # 1. í…Œì´ë¸” ìƒì„±
    create_table = PostgresOperator(
        task_id='create_coingecko_coin_details_table',
        postgres_conn_id='postgres_default',
        sql='create_coingecko_coin_details.sql',
    )
    
    # 2. ì²˜ë¦¬í•  ì½”ì¸ ëª©ë¡ ì¡°íšŒ
    get_coins = PythonOperator(
        task_id='get_target_coin_ids',
        python_callable=get_target_coin_ids,
    )
    
    # 3. ì½”ì¸ ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘
    fetch_details = PythonOperator(
        task_id='fetch_coin_details_batch',
        python_callable=fetch_coin_details_batch,
    )
    
    # 4. ë°ì´í„° ê°€ê³µ ë° ì €ì¥
    process_data = PythonOperator(
        task_id='process_and_store_details',
        python_callable=process_and_store_details,
    )
    
    # Task ì˜ì¡´ì„±
    create_table >> get_coins >> fetch_details >> process_data