from airflow.models import Variable
from datetime import datetime, timedelta
import os
import requests
from decimal import Decimal
import json
import time

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook

# í‘œì¤€ ê²½ë¡œ ì„¤ì •
DAGS_SQL_DIR = os.path.join(os.path.dirname(__file__), "sql")
INITDB_SQL_DIR = os.path.join(os.path.dirname(__file__), "initdb")

# SQL íŒŒì¼ ì½ê¸°
with open(os.path.join(DAGS_SQL_DIR, "upsert_coingecko_coin_details.sql"), encoding="utf-8") as f:
    UPSERT_SQL = f.read()

# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'investment_assistant',
    'start_date': datetime(2025, 1, 1),
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

def get_target_coin_ids(**context):
    """
    ì²˜ë¦¬í•  ì½”ì¸ ID ëª©ë¡ ì¡°íšŒ (ì ì§„ì  í™•ìž¥ ì „ëžµ)
    """
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    # ì„¤ì •
    DAILY_TARGET_COINS = 200  # í•˜ë£¨ ì²˜ë¦¬í•  ì½”ì¸ ìˆ˜
    MAX_TARGET_COINS = 1000   # ìµœëŒ€ ëª©í‘œ ì½”ì¸ ìˆ˜
    
    # ì´ë¯¸ coin details ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œ ì½”ì¸ë“¤ í™•ì¸
    processed_coins = hook.get_first("""
        SELECT COUNT(DISTINCT coingecko_id) 
        FROM coingecko_coin_details 
        WHERE updated_at >= CURRENT_DATE - INTERVAL '30 days';
    """)
    
    processed_count = processed_coins[0] if processed_coins else 0
    
    print(f"ìµœê·¼ 30ì¼ ë‚´ ì²˜ë¦¬ëœ ì½”ì¸: {processed_count}ê°œ")
    
    # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
    if processed_count >= MAX_TARGET_COINS:
        print(f"ëª©í‘œ ë‹¬ì„± ì™„ë£Œ ({processed_count}/{MAX_TARGET_COINS}ê°œ). DAG ì¢…ë£Œ.")
        context['ti'].xcom_push(key='coin_list', value=[])
        return {'status': 'completed', 'processed_count': processed_count}
    
    # ë¯¸ì²˜ë¦¬ ì½”ì¸ ëª©ë¡ ì¡°íšŒ (ì‹œì´ ìˆœ)
    query = """
    WITH unprocessed_coins AS (
        SELECT 
            cg.coingecko_id, 
            cg.symbol, 
            cg.name, 
            cg.market_cap_rank
        FROM coingecko_id_mapping cg
        LEFT JOIN (
            SELECT DISTINCT coingecko_id 
            FROM coingecko_coin_details 
            WHERE updated_at >= CURRENT_DATE - INTERVAL '30 days'
        ) processed ON cg.coingecko_id = processed.coingecko_id
        WHERE processed.coingecko_id IS NULL  -- ë¯¸ì²˜ë¦¬ë§Œ
        AND cg.market_cap_rank IS NOT NULL   -- ìˆœìœ„ê°€ ìžˆëŠ” ê²ƒë§Œ
        AND cg.market_cap_rank <= %s         -- ìƒìœ„ Nê°œë§Œ
    )
    SELECT coingecko_id, symbol, name, market_cap_rank
    FROM unprocessed_coins
    ORDER BY market_cap_rank ASC
    LIMIT %s;
    """
    
    # ë‚¨ì€ ëª©í‘œëŸ‰ì— ë”°ë¼ ì²˜ë¦¬ëŸ‰ ê²°ì •
    remaining_target = min(MAX_TARGET_COINS - processed_count, DAILY_TARGET_COINS)
    
    results = hook.get_records(query, parameters=(MAX_TARGET_COINS, remaining_target))
    coin_list = [{'id': row[0], 'symbol': row[1], 'name': row[2], 'rank': row[3]} for row in results]
    
    print(f"ì˜¤ëŠ˜ ì²˜ë¦¬í•  ì½”ì¸: {len(coin_list)}ê°œ")
    print(f"ì§„í–‰ë¥ : {processed_count + len(coin_list)}/{MAX_TARGET_COINS}ê°œ ({((processed_count + len(coin_list))/MAX_TARGET_COINS*100):.1f}%)")
    
    # ì²˜ë¦¬í•  ì½”ì¸ì´ ìžˆëŠ” ê²½ìš° ìƒìœ„ 5ê°œ ë¡œê·¸ ì¶œë ¥
    if coin_list:
        print("ì˜¤ëŠ˜ ì²˜ë¦¬í•  ìƒìœ„ 5ê°œ ì½”ì¸:")
        for coin in coin_list[:5]:
            print(f"  ìˆœìœ„ {coin['rank']}: {coin['symbol']} ({coin['name']})")
    
    # XComì— ì €ìž¥
    context['ti'].xcom_push(key='coin_list', value=coin_list)
    return {
        'status': 'processing',
        'target_coins': len(coin_list),
        'processed_count': processed_count,
        'progress_percentage': round((processed_count + len(coin_list))/MAX_TARGET_COINS*100, 1)
    }

def fetch_coin_details_batch(**context):
    """
    ì½”ì¸ ìƒì„¸ ì •ë³´ ë°°ì¹˜ ìˆ˜ì§‘ (Rate Limit ê³ ë ¤, API í‚¤ ì ìš©)
    """
    # XComì—ì„œ ì½”ì¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    coin_list = context['ti'].xcom_pull(task_ids='get_target_coin_ids', key='coin_list')
    
    if not coin_list:
        print("ì²˜ë¦¬í•  ì½”ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        context['ti'].xcom_push(key='batch_results', value=[])
        return {'total_processed': 0, 'success_count': 0, 'failed_count': 0}
    
    # API í‚¤ ê°€ì ¸ì˜¤ê¸°
    api_key = Variable.get('COINGECKO_API_KEY_1')
    if not api_key:
        raise ValueError("COINGECKO_API_KEY_1ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    API_BASE_URL = "https://api.coingecko.com/api/v3/coins"
    BATCH_SIZE = 20  # Tickersë³´ë‹¤ í° ë°°ì¹˜ (ë‹¨ì¼ API í˜¸ì¶œì´ë¯€ë¡œ)
    
    all_results = []
    total_batches = (len(coin_list) + BATCH_SIZE - 1) // BATCH_SIZE
    
    print(f"ì „ì²´ {len(coin_list)}ê°œ ì½”ì¸ì„ {total_batches}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬")
    
    # ë°°ì¹˜ë³„ ì²˜ë¦¬
    for i in range(0, len(coin_list), BATCH_SIZE):
        batch = coin_list[i:i + BATCH_SIZE]
        batch_num = (i // BATCH_SIZE) + 1
        
        print(f"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ ì½”ì¸)")
        
        batch_success = 0
        batch_failed = 0
        
        for coin in batch:
            coin_id = coin['id']
            
            # ìž¬ì‹œë„ ë¡œì§
            for attempt in range(3):
                try:
                    url = f"{API_BASE_URL}/{coin_id}"
                    params = {
                        'localization': 'false',
                        'tickers': 'false', 
                        'market_data': 'true',
                        'community_data': 'true',
                        'developer_data': 'true',
                        'sparkline': 'false'
                    }
                    
                    headers = {
                        "accept": "application/json",
                        "x-cg-demo-api-key": api_key
                    }
                    
                    response = requests.get(url, params=params, headers=headers, timeout=30)
                    
                    if response.status_code == 200:
                        coin_data = response.json()
                        all_results.append({
                            'coin_id': coin_id,
                            'status': 'success',
                            'data': coin_data
                        })
                        batch_success += 1
                        break
                        
                    elif response.status_code == 429:  # Rate limit
                        wait_time = 60 * (attempt + 1)
                        print(f"Rate limit ë„ë‹¬. {wait_time}ì´ˆ ëŒ€ê¸°")
                        if attempt < 2:
                            time.sleep(wait_time)
                            continue
                            
                    elif response.status_code == 404:
                        all_results.append({
                            'coin_id': coin_id,
                            'status': 'not_found',
                            'error': f'Coin {coin_id} not found'
                        })
                        batch_failed += 1
                        break
                        
                    else:
                        raise ValueError(f"API ì˜¤ë¥˜: {response.status_code}")
                        
                except requests.RequestException as e:
                    print(f"{coin_id} ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/3): {str(e)}")
                    if attempt < 2:
                        time.sleep(2)
                        continue
            else:
                # ëª¨ë“  ìž¬ì‹œë„ ì‹¤íŒ¨
                all_results.append({
                    'coin_id': coin_id,
                    'status': 'failed',
                    'error': 'All retries failed'
                })
                batch_failed += 1
            
            # Rate Limit ë°©ì§€
            time.sleep(2)  # Tickersë³´ë‹¤ ê¸´ ëŒ€ê¸° ì‹œê°„
        
        print(f"ë°°ì¹˜ {batch_num} ì™„ë£Œ: ì„±ê³µ {batch_success}ê°œ, ì‹¤íŒ¨ {batch_failed}ê°œ")
        
        # ë°°ì¹˜ ê°„ ëŒ€ê¸° (Rate Limit ë°©ì§€)
        if i + BATCH_SIZE < len(coin_list):
            print(f"ë°°ì¹˜ ê°„ ëŒ€ê¸° (60ì´ˆ)")
            time.sleep(60)
    
    # ê²°ê³¼ í†µê³„
    success_count = len([r for r in all_results if r['status'] == 'success'])
    failed_count = len([r for r in all_results if r['status'] in ['failed', 'not_found']])
    
    print(f"ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
    
    # XComì— ì €ìž¥
    context['ti'].xcom_push(key='batch_results', value=all_results)
    
    return {
        'total_processed': len(all_results),
        'success_count': success_count,
        'failed_count': failed_count
    }

def process_and_store_details(**context):
    """
    ìˆ˜ì§‘ëœ ì½”ì¸ ìƒì„¸ ë°ì´í„°ë¥¼ ê°€ê³µí•˜ì—¬ PostgreSQLì— ì €ìž¥
    """
    # XComì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    batch_results = context['ti'].xcom_pull(task_ids='fetch_coin_details_batch', key='batch_results')
    
    if not batch_results:
        raise ValueError("âŒ ì´ì „ íƒœìŠ¤í¬ì—ì„œ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")
    
    # DB ì—°ê²°
    hook = PostgresHook(postgres_conn_id='postgres_default')
    
    success_count = 0
    error_count = 0
    
    print(f"ðŸš€ {len(batch_results)}ê°œ ì½”ì¸ ë°ì´í„° ì €ìž¥ ì‹œìž‘")
    
    for result in batch_results:
        coin_id = result['coin_id']
        
        if result['status'] != 'success':
            error_count += 1
            continue
        
        try:
            coin_data = result['data']
            
            # ë³µìž¡í•œ ì¤‘ì²© ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ë“¤
            def safe_get(data, *keys, default=None):
                """ì¤‘ì²© ë”•ì…”ë„ˆë¦¬ì—ì„œ ì•ˆì „í•˜ê²Œ ê°’ ì¶”ì¶œ"""
                current = data
                for key in keys:
                    if isinstance(current, dict) and key in current:
                        current = current[key]
                    else:
                        return default
                return current
            
            def parse_date(date_str):
                """ë‚ ì§œ ë¬¸ìžì—´ íŒŒì‹±"""
                if date_str:
                    try:
                        return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                    except:
                        return None
                return None
            
            def extract_urls(links_dict, key):
                """ë§í¬ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì²« ë²ˆì§¸ URL ì¶”ì¶œ"""
                urls = safe_get(links_dict, key, [])
                return urls[0] if urls and len(urls) > 0 else None
            
            # ë°ì´í„° ì¶”ì¶œ
            links = safe_get(coin_data, 'links', {})
            market_data = safe_get(coin_data, 'market_data', {})
            community_data = safe_get(coin_data, 'community_data', {})
            developer_data = safe_get(coin_data, 'developer_data', {})
            image = safe_get(coin_data, 'image', {})
            
            # íŒŒë¼ë¯¸í„° ì¤€ë¹„
            params = {
                'coingecko_id': coin_data.get('id'),
                'symbol': coin_data.get('symbol', '').upper(),
                'name': coin_data.get('name', '')[:200],
                'web_slug': coin_data.get('web_slug', '')[:200],
                
                # Tab 1 ë°ì´í„°
                'description_en': safe_get(coin_data, 'description', 'en', '')[:5000],  # TEXT ì œí•œ
                'genesis_date': parse_date(coin_data.get('genesis_date')),
                'country_origin': coin_data.get('country_origin', '')[:100],
                
                # Links
                'homepage_url': extract_urls(links, 'homepage'),
                'blockchain_site': extract_urls(links, 'blockchain_site'),
                'twitter_screen_name': links.get('twitter_screen_name', '')[:100],
                'facebook_username': links.get('facebook_username', '')[:100],
                'telegram_channel_identifier': links.get('telegram_channel_identifier', '')[:100],
                'subreddit_url': links.get('subreddit_url', '')[:500],
                'github_repos': json.dumps(links.get('repos_url', {})) if links.get('repos_url') else None,
                
                # Images
                'image_thumb': image.get('thumb', '')[:500],
                'image_small': image.get('small', '')[:500],
                'image_large': image.get('large', '')[:500],
                
                # Categories
                'categories': json.dumps(coin_data.get('categories', [])),
                
                # Market Data (Tab 3)
                'current_price_usd': Decimal(str(safe_get(market_data, 'current_price', 'usd', 0))),
                'current_price_krw': Decimal(str(safe_get(market_data, 'current_price', 'krw', 0))) if safe_get(market_data, 'current_price', 'krw') else None,
                'market_cap_usd': int(safe_get(market_data, 'market_cap', 'usd', 0)) if safe_get(market_data, 'market_cap', 'usd') else None,
                'market_cap_rank': market_data.get('market_cap_rank'),
                'total_volume_usd': int(safe_get(market_data, 'total_volume', 'usd', 0)) if safe_get(market_data, 'total_volume', 'usd') else None,
                
                # ATH/ATL
                'ath_usd': Decimal(str(safe_get(market_data, 'ath', 'usd', 0))) if safe_get(market_data, 'ath', 'usd') else None,
                'ath_change_percentage': Decimal(str(safe_get(market_data, 'ath_change_percentage', 'usd', 0))) if safe_get(market_data, 'ath_change_percentage', 'usd') else None,
                'ath_date': parse_date(safe_get(market_data, 'ath_date', 'usd')),
                'atl_usd': Decimal(str(safe_get(market_data, 'atl', 'usd', 0))) if safe_get(market_data, 'atl', 'usd') else None,
                'atl_change_percentage': Decimal(str(safe_get(market_data, 'atl_change_percentage', 'usd', 0))) if safe_get(market_data, 'atl_change_percentage', 'usd') else None,
                'atl_date': parse_date(safe_get(market_data, 'atl_date', 'usd')),
                
                # Supply Data
                'total_supply': Decimal(str(market_data.get('total_supply', 0))) if market_data.get('total_supply') else None,
                'circulating_supply': Decimal(str(market_data.get('circulating_supply', 0))) if market_data.get('circulating_supply') else None,
                'max_supply': Decimal(str(market_data.get('max_supply', 0))) if market_data.get('max_supply') else None,
                
                # Price Changes
                'price_change_24h_usd': Decimal(str(market_data.get('price_change_24h', 0))),
                'price_change_percentage_24h': Decimal(str(market_data.get('price_change_percentage_24h', 0))),
                'price_change_percentage_7d': Decimal(str(market_data.get('price_change_percentage_7d', 0))),
                'price_change_percentage_30d': Decimal(str(market_data.get('price_change_percentage_30d', 0))),
                
                # Community Data (Tab 2)
                'community_score': Decimal(str(coin_data.get('community_score', 0))) if coin_data.get('community_score') else None,
                'twitter_followers': community_data.get('twitter_followers'),
                'reddit_subscribers': community_data.get('reddit_subscribers'),
                'telegram_channel_user_count': community_data.get('telegram_channel_user_count'),
                
                # Developer Data (Tab 2)
                'developer_score': Decimal(str(coin_data.get('developer_score', 0))) if coin_data.get('developer_score') else None,
                'forks': developer_data.get('forks'),
                'stars': developer_data.get('stars'),
                'total_issues': developer_data.get('total_issues'),
                'closed_issues': developer_data.get('closed_issues'),
                'commit_count_4_weeks': developer_data.get('commit_count_4_weeks'),
                
                # Other Scores
                'public_interest_score': Decimal(str(coin_data.get('public_interest_score', 0))) if coin_data.get('public_interest_score') else None,
                'liquidity_score': Decimal(str(coin_data.get('liquidity_score', 0))) if coin_data.get('liquidity_score') else None,
                
                # Timestamps
                'coingecko_last_updated': parse_date(coin_data.get('last_updated'))
            }
            
            # SQL ì‹¤í–‰
            hook.run(UPSERT_SQL, parameters=params)
            success_count += 1
            
        except Exception as e:
            print(f"âŒ ì½”ì¸ {coin_id} ì €ìž¥ ì‹¤íŒ¨: {str(e)}")
            error_count += 1
            continue
    
    print(f"âœ… ë°ì´í„° ì €ìž¥ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨")
    
    return {
        'success_count': success_count,
        'error_count': error_count,
        'execution_time': context['execution_date'].isoformat()
    }

# DAG ì •ì˜
with DAG(
    dag_id='ingest_coingecko_coin_details_k8s',
    default_args=default_args,
    schedule_interval='@daily',  # ë§¤ì¼ ì‹¤í–‰
    catchup=False,
    description='CoinGecko ì½”ì¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘',
    template_searchpath=[INITDB_SQL_DIR],
    tags=['coingecko', 'crypto', 'details', 'daily'],
) as dag:
    
    # 1. í…Œì´ë¸” ìƒì„±
    create_table = PostgresOperator(
        task_id='create_coingecko_coin_details_table',
        postgres_conn_id='postgres_default',
        sql='create_coingecko_coin_details.sql',
    )
    
    # 2. ì²˜ë¦¬í•  ì½”ì¸ ëª©ë¡ ì¡°íšŒ
    get_coins = PythonOperator(
        task_id='get_target_coin_ids',
        python_callable=get_target_coin_ids,
    )
    
    # 3. ì½”ì¸ ìƒì„¸ ë°ì´í„° ìˆ˜ì§‘
    fetch_details = PythonOperator(
        task_id='fetch_coin_details_batch',
        python_callable=fetch_coin_details_batch,
    )
    
    # 4. ë°ì´í„° ê°€ê³µ ë° ì €ìž¥
    process_data = PythonOperator(
        task_id='process_and_store_details',
        python_callable=process_and_store_details,
    )
    
    # Task ì˜ì¡´ì„±
    create_table >> get_coins >> fetch_details >> process_data