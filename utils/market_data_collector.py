# utils/market_data_collector.py
from airflow.hooks.postgres_hook import PostgresHook
from datetime import datetime, timedelta
import logging
import time
import statistics

logger = logging.getLogger(__name__)

class MarketAnalyzer:
    def __init__(self, pg_hook, market_collector=None):
        self.pg_hook = pg_hook
        self.market_collector = market_collector or MarketDataCollector()
    
    def calculate_price_changes(self, symbol, post_timestamp, market_data):
        """ê²Œì‹œê¸€ ì „í›„ ê°€ê²© ë³€í™” ë¶„ì„"""
        start_time = time.time()

        try:
            price_timeline = market_data.get('price_timeline', [])
            if not price_timeline:
                return {}

            # ê²Œì‹œê¸€ ì‹œì  ê¸°ì¤€ ê°€ê²© ì°¾ê¸°
            post_price = self._get_price_near_time(price_timeline, post_timestamp)
            if not post_price:
                return {}

            # ì‹œê°„ë³„ ê°€ê²© ë³€í™” ê³„ì‚°
            changes = {}

            # 1ì‹œê°„ í›„ (ì‹¤ì œë¡œëŠ” ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„°í¬ì¸íŠ¸)
            hour_1_time = post_timestamp + timedelta(hours=1)
            hour_1_price = self._get_price_near_time(price_timeline, hour_1_time)
            if hour_1_price:
                changes['1h_change'] = round(((hour_1_price - post_price) / post_price) * 100, 2)

            # 12ì‹œê°„ í›„
            hour_12_time = post_timestamp + timedelta(hours=12)
            hour_12_price = self._get_price_near_time(price_timeline, hour_12_time)
            if hour_12_price:
                changes['12h_change'] = round(((hour_12_price - post_price) / post_price) * 100, 2)

            # 24ì‹œê°„ í›„ (ë˜ëŠ” ë‹¤ìŒ ê±°ë˜ì¼)
            if self.market_collector.is_crypto_symbol(symbol):
                # ì•”í˜¸í™”íëŠ” 24ì‹œê°„ ê±°ë˜
                hour_24_time = post_timestamp + timedelta(hours=24)
                hour_24_price = self._get_price_near_time(price_timeline, hour_24_time)
                if hour_24_price:
                    changes['24h_change'] = round(((hour_24_price - post_price) / post_price) * 100, 2)
            else:
                # ì£¼ì‹ì€ ë‹¤ìŒ ê±°ë˜ì¼ ê¸°ì¤€
                next_trading_day = self._get_next_trading_day(post_timestamp)
                next_day_price = self._get_average_price_around_time(price_timeline, next_trading_day, hours=1)
                if next_day_price:
                    changes['next_day_change'] = round(((next_day_price - post_price) / post_price) * 100, 2)

            changes['base_price'] = post_price

            # ì‹œê°„ ì¸¡ì • ë¡œê¹…
            elapsed = time.time() - start_time
            logger.info(f"ğŸ’° Price analysis for {symbol}: {elapsed:.2f}s")

            return changes

        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ Price analysis failed for {symbol} in {elapsed:.2f}s: {e}")
            return {}
    
    def calculate_volume_changes(self, symbol, post_timestamp, market_data):
        """[ìˆ˜ì •] ë°ì´í„° ì¢…ë¥˜ì— ë”°ë¼ ì˜¬ë°”ë¥¸ ë³¼ë¥¨ ë¶„ì„ì„ í˜¸ì¶œí•˜ëŠ” ì»¨íŠ¸ë¡¤ íƒ€ì›Œ"""
        price_timeline = market_data.get('price_timeline', [])
        if not price_timeline:
            return {}

        # Bithumb ë°ì´í„° (ëˆ„ì  ê±°ë˜ëŸ‰)ì¸ì§€ í™•ì¸
        if 'acc_volume' in price_timeline[0]:
            return self._calculate_cumulative_volume_change(symbol, post_timestamp, price_timeline)
        # S&P 500 / ETF ë°ì´í„° (ê°œë³„ ê±°ë˜ëŸ‰)ì¸ì§€ í™•ì¸
        elif 'volume' in price_timeline[0]:
            return self._calculate_average_volume_change(symbol, post_timestamp, price_timeline)
        
        return {}

    def _calculate_cumulative_volume_change(self, symbol, post_timestamp, timeline):
        """[ì‹ ê·œ] ëˆ„ì  ê±°ë˜ëŸ‰(acc_volume)ì„ ì‚¬ìš©í•œ ë¶„ì„ (Bithumb ì „ìš©)"""
        start_time = time.time()
        try:
            time_before_1h = post_timestamp - timedelta(hours=1)
            time_at_post = post_timestamp
            time_after_1h = post_timestamp + timedelta(hours=1)

            acc_vol_before_1h = self._get_acc_volume_near_time(timeline, time_before_1h)
            acc_vol_at_post = self._get_acc_volume_near_time(timeline, time_at_post)
            acc_vol_after_1h = self._get_acc_volume_near_time(timeline, time_after_1h)

            volume_changes = {}
            volume_in_prior_hour, volume_in_post_hour = None, None

            if acc_vol_before_1h is not None and acc_vol_at_post is not None:
                volume_in_prior_hour = acc_vol_at_post - acc_vol_before_1h
                volume_changes['volume_in_prior_hour'] = round(volume_in_prior_hour, 2)

            if acc_vol_at_post is not None and acc_vol_after_1h is not None:
                # ìˆ˜ì •ëœ ë¶€ë¶„
                volume_in_post_hour = acc_vol_after_1h - acc_vol_at_post
                volume_changes['volume_in_post_hour'] = round(volume_in_post_hour, 2)

            if volume_in_prior_hour and volume_in_post_hour and volume_in_prior_hour > 0:
                spike_ratio = volume_in_post_hour / volume_in_prior_hour
                volume_changes['volume_spike_ratio_1h'] = round(spike_ratio, 2)

            elapsed = time.time() - start_time
            logger.info(f"ğŸ“Š Cumulative Volume analysis for {symbol}: {elapsed:.2f}s")
            return volume_changes
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ Cumulative Volume analysis failed for {symbol} in {elapsed:.2f}s: {e}")
            return {}

    def _calculate_average_volume_change(self, symbol, post_timestamp, timeline):
        """[ì‹ ê·œ] ê°œë³„ ê±°ë˜ëŸ‰(volume) í‰ê· ì„ ì‚¬ìš©í•œ ë¶„ì„ (S&P500, ETF ì „ìš©)"""
        start_time = time.time()
        try:
            before_time = post_timestamp - timedelta(hours=1)
            before_volume = self._get_average_volume_around_time(timeline, before_time, hours=1)

            after_time = post_timestamp
            after_volume = self._get_average_volume_around_time(timeline, after_time, hours=1)

            volume_changes = {}
            if before_volume is not None and after_volume is not None and before_volume > 0:
                volume_changes['avg_volume_change_1h'] = round(((after_volume - before_volume) / before_volume) * 100, 2)
            
            volume_changes['avg_volume_before'] = before_volume
            volume_changes['avg_volume_after'] = after_volume

            elapsed = time.time() - start_time
            logger.info(f"ğŸ“Š Average Volume analysis for {symbol}: {elapsed:.2f}s")
            return volume_changes
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"âŒ Average Volume analysis failed for {symbol} in {elapsed:.2f}s: {e}")
            return {}

    def _get_price_near_time(self, timeline, target_time, tolerance_hours=2):
        """íŠ¹ì • ì‹œê°„ ê·¼ì²˜ì˜ ê°€ê²© ì°¾ê¸°"""
        target_timestamp = target_time.timestamp()
        closest_price = None
        min_diff = float('inf')

        for point in timeline:
            try:
                point_time = datetime.fromisoformat(point['timestamp'].replace('Z', '+00:00'))
                time_diff = abs((point_time.timestamp() - target_timestamp))

                # tolerance_hours ì‹œê°„ ë‚´ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©
                if time_diff <= tolerance_hours * 3600 and time_diff < min_diff:
                    min_diff = time_diff
                    closest_price = float(point['price'])
            except:
                continue

        return closest_price
    
    def _get_average_price_around_time(self, timeline, target_time, hours=1):
        """íŠ¹ì • ì‹œê°„ ì „í›„ ì¼ì • ì‹œê°„ì˜ í‰ê·  ê°€ê²©"""
        start_time = target_time - timedelta(hours=hours/2)
        end_time = target_time + timedelta(hours=hours/2)

        prices = []
        for point in timeline:
            try:
                point_time = datetime.fromisoformat(point['timestamp'].replace('Z', '+00:00'))
                if start_time <= point_time <= end_time:
                    prices.append(float(point['price']))
            except:
                continue

        return statistics.mean(prices) if prices else None
    
    def _get_average_volume_around_time(self, timeline, target_time, hours=1):
        """íŠ¹ì • ì‹œê°„ ì „í›„ ì¼ì • ì‹œê°„ì˜ í‰ê·  ê±°ë˜ëŸ‰"""
        start_time = target_time - timedelta(hours=hours/2)
        end_time = target_time + timedelta(hours=hours/2)

        volumes = []
        for point in timeline:
            try:
                point_time = datetime.fromisoformat(point['timestamp'].replace('Z', '+00:00'))
                # [ìˆ˜ì •] point ë”•ì…”ë„ˆë¦¬ì—ì„œ 'volume' í‚¤ì˜ ê°’ì„ ì§ì ‘ í™•ì¸í•˜ê³ , 0ì¸ ê²½ìš°ë„ ì œì™¸
                if start_time <= point_time <= end_time:
                    volume_value = point.get('volume')
                    if volume_value is not None and volume_value > 0:
                        volumes.append(float(volume_value))
            except:
                continue

        return statistics.mean(volumes) if volumes else None
    
    def _get_next_trading_day(self, post_timestamp):
        """ë‹¤ìŒ ê±°ë˜ì¼ êµ¬í•˜ê¸° (ì£¼ë§ ì œì™¸)"""
        next_day = post_timestamp + timedelta(days=1)
        
        # ì£¼ë§ì´ë©´ ë‹¤ìŒ ì›”ìš”ì¼ë¡œ
        while next_day.weekday() >= 5:  # 5=í† ìš”ì¼, 6=ì¼ìš”ì¼
            next_day += timedelta(days=1)
        
        # ê±°ë˜ ì‹œê°„ëŒ€ë¡œ ì¡°ì • (ì˜¤ì „ 10ì‹œ)
        next_day = next_day.replace(hour=10, minute=0, second=0, microsecond=0)
        return next_day

    def _get_acc_volume_near_time(self, timeline, target_time, tolerance_hours=2):
        """[ì¶”ê°€] íŠ¹ì • ì‹œê°„ ê·¼ì²˜ì˜ ëˆ„ì  ê±°ë˜ëŸ‰(acc_volume) ì°¾ê¸°"""
        target_timestamp = target_time.timestamp()
        closest_volume = None
        min_diff = float('inf')

        for point in timeline:
            try:
                point_time = datetime.fromisoformat(point['timestamp'].replace('Z', '+00:00'))
                time_diff = abs((point_time.timestamp() - target_timestamp))

                if time_diff <= tolerance_hours * 3600 and time_diff < min_diff:
                    min_diff = time_diff
                    # 'price' ëŒ€ì‹  'acc_volume' í‚¤ì˜ ê°’ì„ ê°€ì ¸ì˜´
                    closest_volume = float(point['acc_volume'])
            except:
                continue

        return closest_volume

class MarketDataCollector:
    def __init__(self):
        self.pg_hook = PostgresHook(postgres_conn_id='postgres_default')
        self._sp500_symbols_cache = None
        self._crypto_symbols_cache = None
        self._etf_symbols_cache = None # [ì¶”ê°€] ETF ì‹¬ë³¼ ìºì‹œ ë³€ìˆ˜
    
    def collect_market_data(self, affected_assets, post_timestamp):
        """ì˜í–¥ë°›ì€ ìì‚°ë“¤ì˜ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘"""
        market_data = {}

        start_time = time.time()
        for asset_info in affected_assets:
            symbol = asset_info['symbol']
            
            try:
                # ê°€ê²© íƒ€ì„ë¼ì¸ ë°ì´í„°
                price_timeline = self._get_price_timeline(symbol, post_timestamp)
                
                if price_timeline:
                    market_data[symbol] = {
                        'price_timeline': price_timeline,
                        'data_source': self._get_data_source(symbol),
                        'asset_info': asset_info
                    }
                    
            except Exception as e:
                logger.error(f"Failed to collect market data for {symbol}: {e}")
                continue
        end_time = time.time()
        logger.info(f"Market data collection time: {end_time - start_time} seconds")
        return market_data
    
    def _get_price_timeline(self, symbol, post_timestamp):
        """ìì‚°ë³„ ê°€ê²© íƒ€ì„ë¼ì¸ ìˆ˜ì§‘ - í™•ì¥ëœ ì‹œê°„ ë²”ìœ„"""
        
        # SP500 ì£¼ì‹ì¸ì§€ í™•ì¸ (5ì¼ ë²”ìœ„)
        if self._is_sp500_symbol(symbol):
            start_time = post_timestamp - timedelta(days=2)
            end_time = post_timestamp + timedelta(days=2)
            return self._get_sp500_timeline(symbol, start_time, end_time)
        
        # [ì¶”ê°€] ETFì¸ì§€ í™•ì¸
        elif self.is_etf_symbol(symbol):
            start_time = post_timestamp - timedelta(days=2)
            end_time = post_timestamp + timedelta(days=2)
            return self._get_etf_timeline(symbol, start_time, end_time)

        # ì•”í˜¸í™”íì¸ì§€ í™•ì¸ (3ì¼ ë²”ìœ„)
        elif self.is_crypto_symbol(symbol):
            start_time = post_timestamp - timedelta(days=1)
            end_time = post_timestamp + timedelta(days=1)
            return self._get_crypto_timeline(symbol, start_time, end_time)
        
        return []
    
    def _is_sp500_symbol(self, symbol):
        """SP500 ì‹¬ë³¼ì¸ì§€ í™•ì¸ - DBì—ì„œ ë™ì  ì¡°íšŒ"""
        if self._sp500_symbols_cache is None:
            try:
                query = "SELECT DISTINCT symbol FROM sp500_websocket_trades LIMIT 1000"
                results = self.pg_hook.get_records(query)
                self._sp500_symbols_cache = {row[0] for row in results}
                logger.info(f"Loaded {len(self._sp500_symbols_cache)} SP500 symbols from DB")
            except Exception as e:
                logger.error(f"Failed to load SP500 symbols: {e}")
                self._sp500_symbols_cache = set()
        
        return symbol in self._sp500_symbols_cache
    # [ì¶”ê°€] ETF ì‹¬ë³¼ í™•ì¸ ë¡œì§
    def is_etf_symbol(self, symbol):
        """ETF ì‹¬ë³¼ì¸ì§€ í™•ì¸ - DBì—ì„œ ë™ì  ì¡°íšŒ"""
        if self._etf_symbols_cache is None:
            try:
                query = "SELECT DISTINCT symbol FROM etf_realtime_prices LIMIT 1000"
                results = self.pg_hook.get_records(query)
                self._etf_symbols_cache = {row[0] for row in results}
                logger.info(f"Loaded {len(self._etf_symbols_cache)} ETF symbols from DB")
            except Exception as e:
                logger.error(f"Failed to load ETF symbols: {e}")
                self._etf_symbols_cache = set()
        return symbol in self._etf_symbols_cache
    
    
    def is_crypto_symbol(self, symbol):
        """ì•”í˜¸í™”í ì‹¬ë³¼ì¸ì§€ í™•ì¸ - DBì—ì„œ ë™ì  ì¡°íšŒ"""
        if self._crypto_symbols_cache is None:
            try:
                query = """
                SELECT DISTINCT REPLACE(market, 'KRW-', '') as symbol 
                FROM bithumb_ticker 
                WHERE market LIKE 'KRW-%'
                LIMIT 1000
                """
                results = self.pg_hook.get_records(query)
                self._crypto_symbols_cache = {row[0] for row in results}
                logger.info(f"Loaded {len(self._crypto_symbols_cache)} crypto symbols from DB")
            except Exception as e:
                logger.error(f"Failed to load crypto symbols: {e}")
                self._crypto_symbols_cache = set()
        
        return symbol in self._crypto_symbols_cache
    
    def _get_sp500_timeline(self, symbol, start_time, end_time):
        """SP500 ê°€ê²© íƒ€ì„ë¼ì¸ - 5ì¼ ë²”ìœ„"""
        try:
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
            start_ms = int(start_time.timestamp() * 1000)
            end_ms = int(end_time.timestamp() * 1000)
            
            query = """
            SELECT timestamp_ms, price, volume
            FROM sp500_websocket_trades 
            WHERE symbol = %s 
                AND timestamp_ms BETWEEN %s AND %s
            ORDER BY timestamp_ms
            LIMIT 5000
            """
            
            results = self.pg_hook.get_records(query, parameters=[symbol, start_ms, end_ms])
            
            return [{
                'timestamp': datetime.fromtimestamp(row[0]/1000).isoformat(),
                'price': float(row[1]),
                'volume': int(row[2]) if row[2] else 0
            } for row in results]
            
        except Exception as e:
            logger.error(f"Failed to get SP500 timeline for {symbol}: {e}")
            return []
    def _get_etf_timeline(self, symbol, start_time, end_time):
        """ETF ê°€ê²© íƒ€ì„ë¼ì¸ - S&P500ê³¼ ë™ì¼í•œ ë¡œì§"""
        try:
            start_ms = int(start_time.timestamp() * 1000)
            end_ms = int(end_time.timestamp() * 1000)
            query = """
            SELECT timestamp_ms, price, volume
            FROM etf_realtime_prices -- í…Œì´ë¸” ì´ë¦„ë§Œ ë³€ê²½
            WHERE symbol = %s 
                AND timestamp_ms BETWEEN %s AND %s
            ORDER BY timestamp_ms
            LIMIT 5000
            """
            results = self.pg_hook.get_records(query, parameters=[symbol, start_ms, end_ms])
            return [{
                'timestamp': datetime.fromtimestamp(row[0]/1000).isoformat(),
                'price': float(row[1]),
                'volume': int(row[2]) if row[2] else 0
            } for row in results]
        except Exception as e:
            logger.error(f"Failed to get ETF timeline for {symbol}: {e}")
            return []
    
    def _get_crypto_timeline(self, symbol, start_time, end_time):
        """ì•”í˜¸í™”í ê°€ê²© íƒ€ì„ë¼ì¸ - 3ì¼ ë²”ìœ„"""
        try:
            # KRW- ì ‘ë‘ì‚¬ ì¶”ê°€í•´ì„œ ë¹—ì¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            bithumb_market = f"KRW-{symbol}"

            # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
            start_ms = int(start_time.timestamp() * 1000)
            end_ms = int(end_time.timestamp() * 1000)

            query = """
            SELECT trade_timestamp,
                CAST(trade_price AS DECIMAL) as price,
                CAST(trade_volume AS DECIMAL) as volume,
                CAST(acc_trade_volume AS DECIMAL) as acc_volume
            FROM bithumb_ticker
            WHERE market = %s
                AND trade_timestamp BETWEEN %s AND %s
                -- íƒ€ì…ì„ ëª…í™•íˆ í•˜ì—¬ ì•ˆì „í•˜ê²Œ í•„í„°ë§
                AND trade_price::text ~ '^[0-9]+\.?[0-9]*$'
            ORDER BY trade_timestamp
            LIMIT 3000
            """

            results = self.pg_hook.get_records(query, parameters=[bithumb_market, start_ms, end_ms])

            return [{
                'timestamp': datetime.fromtimestamp(row[0]/1000).isoformat(),
                'price': float(row[1]) if row[1] else 0,
                'volume': float(row[2]) if row[2] else 0,
                'acc_volume': float(row[3]) if row[3] else 0
            } for row in results]

        except Exception as e:
            logger.error(f"Failed to get crypto timeline for {symbol}: {e}")
            return []
    
    def _get_data_source(self, symbol):
        """ë°ì´í„° ì†ŒìŠ¤ ì‹ë³„"""
        if self._is_sp500_symbol(symbol):
            return 'sp500_realtime'
        elif self.is_etf_symbol(symbol): # [ì¶”ê°€]
            return 'etf_realtime'
        elif self.is_crypto_symbol(symbol):
            return 'bithumb_realtime'
        return 'unknown'